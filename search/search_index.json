{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Course overview \u00b6 For the requirements, please visit the official data sheet . For the schedule of the course and the deadlines for submission, please refer to the course site in Moodle. Submitting the solutions \u00b6 Each lab must be submitted in a personal git repository. Please refer to the detailed guideline here . You must carefully study these guidelines! IMPORTANT The submissions of the lab exercises must follow these guidelines. Submissions not following these guidelines are not graded. Workflow errors, i.e., not following the guidelines (e.g., not assigning the right person or not assigning at all, are penalized. Screenshots \u00b6 Some of the exercises require you to create a screenshot. This screenshot is proof of the completion of the exercise. The expected content of these screenshots is detailed in the exercise description. The screenshot may include the entire desktop or just the required portion of the screen. You must submit the screenshots as part of the solution code, uploaded to the git repository. The repositories are private; only you and the instructions can access them. If there is any content on the screenshot that is not relevant to the exercise and you would like to remove it, you can obscure these parts. Grading \u00b6 Each laboratory is graded on a 1-5 scale. You must submit each lab by the deadline. The laboratory grade is calculated based on the 20+3 points you can earn in each lab as follows: 0-7.5 point: failed 8-10.5 point: pass 11-13.5 point: satisfactory 14-16.5 point: good 17-20+ points: very good The extra +3 points are optional; if you do them, it is added to the points. In the automated evaluation, these extra 3 points will appear as \"imsc\"; please ignore this (that is for the Hungarian students). The final grade will be the mathematically correct average of the individual (1-5 scale) grades. If you do not attend a lab or do not submit it until the deadline, it will be counted as grade 1 in the average. Some of the exercises are evaluated automatically . Your code will be executed; therefore, you must follow the exercise descriptions precisely (e.g., use the provided code skeleton, change only the allowed parts of the code, etc.). You will receive a preliminary result about your submission in GitHub; see in the guideline here ). If there are some issues you need to diagnose, the entire log of the execution is available for you on the GitHub Actions web page. A short introduction is provided here . Our expectations regarding the labs \u00b6 Where should I upload the solution? See above. Individual work at home? Since your work is graded, you are expected to submit your own solution. This does not mean that you cannot ask or give help to others. But it prohibits submitting a work created by someone else. This is the reason we ask for screenshots: these verify the process of completing the exercises. Submitting the work of someone else: Refer to the Ethical codex and the Code of Studies. One lab is just 4 hours, right? No. This course is 3 credits, which (officially) translates to approx. 90 hours of work invested throughout the semester. The lab is not just the 4 hours you spend with the instructor; it also involves preliminary preparation and finishing/completing the tasks at home. My code contains a small typo, and I received no grade. You are expected to write code that works! You are completing the exercises in front of a computer, so you have everything you need to check yourself. Your code must compile and must run. If the behavior is not entirely correct, that is accepted. But if it does not even compile, it will not be graded. Just imagine what would happen if you committed code that does not compile at your workplace? If I am working at home, how do I get help? Talk to your lab instructor. The instructor does not help. Why? You might not be given the right solution if you face a problem. But this does not mean you get no help. You are encouraged to investigate your problems, search for solutions, and ask specific issues. You must demonstrate that you are a professional! How should I ask questions then? In short: https://stackoverflow.com/help/how-to-ask . In more detail: If you are stuck, first, make an effort to understand your problem. The problem is not that \"it does not work\" or \"I don't know how to do it.\" You can ask good questions once you understand the problem and have tested some solutions already. So the answer is Google and StackOverflow? No. Everything you need here, you should already know. Google is an excellent tool, and StackOverflow is even better. However... You also need to understand the answer you find here. The answer you find here might be a solution to some problem, but not necessarily your issue. All these deadlines and rules! A software developer, better yet, an engineer, must be prepared to write code and work within the scope of prescribed rules. The world is complex, and complexity is often managed with rules. If you have some time, check what Robert C. Martin (Bob Martin, \"Uncle Bob\") has to say about the origins of the software developer profession: https://www.youtube.com/watch?v=ecIWPzGEbFc Pull requests welcome As a student of this course, you can earn extra credit by contributing to the materials! Open a pull request to fix an error or contribute to the contents in any way! Check the link to the repository in the upper right corner. License The materials provided here are created for the students of course BMEVIAUAC09. The usage of these materials outside the scope of teaching or learning this particular course is only granted if the source and authors are contributed. These materials are to be viewed within the context of the course. For any other usage scenarios, the material is provided as-is.","title":"Course overview"},{"location":"#course-overview","text":"For the requirements, please visit the official data sheet . For the schedule of the course and the deadlines for submission, please refer to the course site in Moodle.","title":"Course overview"},{"location":"#submitting-the-solutions","text":"Each lab must be submitted in a personal git repository. Please refer to the detailed guideline here . You must carefully study these guidelines! IMPORTANT The submissions of the lab exercises must follow these guidelines. Submissions not following these guidelines are not graded. Workflow errors, i.e., not following the guidelines (e.g., not assigning the right person or not assigning at all, are penalized.","title":"Submitting the solutions"},{"location":"#screenshots","text":"Some of the exercises require you to create a screenshot. This screenshot is proof of the completion of the exercise. The expected content of these screenshots is detailed in the exercise description. The screenshot may include the entire desktop or just the required portion of the screen. You must submit the screenshots as part of the solution code, uploaded to the git repository. The repositories are private; only you and the instructions can access them. If there is any content on the screenshot that is not relevant to the exercise and you would like to remove it, you can obscure these parts.","title":"Screenshots"},{"location":"#grading","text":"Each laboratory is graded on a 1-5 scale. You must submit each lab by the deadline. The laboratory grade is calculated based on the 20+3 points you can earn in each lab as follows: 0-7.5 point: failed 8-10.5 point: pass 11-13.5 point: satisfactory 14-16.5 point: good 17-20+ points: very good The extra +3 points are optional; if you do them, it is added to the points. In the automated evaluation, these extra 3 points will appear as \"imsc\"; please ignore this (that is for the Hungarian students). The final grade will be the mathematically correct average of the individual (1-5 scale) grades. If you do not attend a lab or do not submit it until the deadline, it will be counted as grade 1 in the average. Some of the exercises are evaluated automatically . Your code will be executed; therefore, you must follow the exercise descriptions precisely (e.g., use the provided code skeleton, change only the allowed parts of the code, etc.). You will receive a preliminary result about your submission in GitHub; see in the guideline here ). If there are some issues you need to diagnose, the entire log of the execution is available for you on the GitHub Actions web page. A short introduction is provided here .","title":"Grading"},{"location":"#our-expectations-regarding-the-labs","text":"Where should I upload the solution? See above. Individual work at home? Since your work is graded, you are expected to submit your own solution. This does not mean that you cannot ask or give help to others. But it prohibits submitting a work created by someone else. This is the reason we ask for screenshots: these verify the process of completing the exercises. Submitting the work of someone else: Refer to the Ethical codex and the Code of Studies. One lab is just 4 hours, right? No. This course is 3 credits, which (officially) translates to approx. 90 hours of work invested throughout the semester. The lab is not just the 4 hours you spend with the instructor; it also involves preliminary preparation and finishing/completing the tasks at home. My code contains a small typo, and I received no grade. You are expected to write code that works! You are completing the exercises in front of a computer, so you have everything you need to check yourself. Your code must compile and must run. If the behavior is not entirely correct, that is accepted. But if it does not even compile, it will not be graded. Just imagine what would happen if you committed code that does not compile at your workplace? If I am working at home, how do I get help? Talk to your lab instructor. The instructor does not help. Why? You might not be given the right solution if you face a problem. But this does not mean you get no help. You are encouraged to investigate your problems, search for solutions, and ask specific issues. You must demonstrate that you are a professional! How should I ask questions then? In short: https://stackoverflow.com/help/how-to-ask . In more detail: If you are stuck, first, make an effort to understand your problem. The problem is not that \"it does not work\" or \"I don't know how to do it.\" You can ask good questions once you understand the problem and have tested some solutions already. So the answer is Google and StackOverflow? No. Everything you need here, you should already know. Google is an excellent tool, and StackOverflow is even better. However... You also need to understand the answer you find here. The answer you find here might be a solution to some problem, but not necessarily your issue. All these deadlines and rules! A software developer, better yet, an engineer, must be prepared to write code and work within the scope of prescribed rules. The world is complex, and complexity is often managed with rules. If you have some time, check what Robert C. Martin (Bob Martin, \"Uncle Bob\") has to say about the origins of the software developer profession: https://www.youtube.com/watch?v=ecIWPzGEbFc Pull requests welcome As a student of this course, you can earn extra credit by contributing to the materials! Open a pull request to fix an error or contribute to the contents in any way! Check the link to the repository in the upper right corner. License The materials provided here are created for the students of course BMEVIAUAC09. The usage of these materials outside the scope of teaching or learning this particular course is only granted if the source and authors are contributed. These materials are to be viewed within the context of the course. For any other usage scenarios, the material is provided as-is.","title":"Our expectations regarding the labs"},{"location":"GitHub-Actions/","text":"Using GitHub Actions \u00b6 The semi-automatic evaluation of the exercises is based on GitHub Actions . It is a CI system capable of running jobs on git repositories. We use this system, for example, to compile your code and test it. You will receive a notification about the results in a pull request. But if you need more details, such as checking the application logs, you can access these using the GitHub web interface under Actions . Here, you will see a list of Workflows . By selecting one (e.g., the last one is always at the top of the list), you see this workflow's details. To get to the logs, you need to click once more on the left. The log will be on the right side. Each green checkmark is a successful step. These steps do not correspond to your exercises; these describe the evaluation process. These steps include preparations, such as setting up the .NET environment for compiling your code (since each workflow starts in a clean environment, these steps are performed each time). Most of these steps should be successful, even if your submission contains an error. The two exceptions when these tasks might fail due to your changes are: (1) if neptun.txt is missing, or (2) your C# code does not compile. The neptun.txt is mandatory, and no evaluation is performed until that is provided. The C# compilation is a step that must succeed; otherwise, your application cannot be started. There might be transient errors in these workflows. An example is when a download, such as the download of the .NET environment fails. The workflow execution can be repeated if this occurs. Retrying the execution may only help if the problem is indeed transient; a retry will not resolve a C# compilation error. (You can deduce the cause from the name of the step and the error message.) You might also be able to access the application logs. E.g., when testing a .NET application, it is started, and the logs will be printed here. The image below shows the initialization of an Entity Framework application, where you can also see the translated and executed SQL commands. (You would see the same in Visual Studio Output while debugging.) The content here, obviously, depends on the actual exercise.","title":"Using GitHub Actions"},{"location":"GitHub-Actions/#using-github-actions","text":"The semi-automatic evaluation of the exercises is based on GitHub Actions . It is a CI system capable of running jobs on git repositories. We use this system, for example, to compile your code and test it. You will receive a notification about the results in a pull request. But if you need more details, such as checking the application logs, you can access these using the GitHub web interface under Actions . Here, you will see a list of Workflows . By selecting one (e.g., the last one is always at the top of the list), you see this workflow's details. To get to the logs, you need to click once more on the left. The log will be on the right side. Each green checkmark is a successful step. These steps do not correspond to your exercises; these describe the evaluation process. These steps include preparations, such as setting up the .NET environment for compiling your code (since each workflow starts in a clean environment, these steps are performed each time). Most of these steps should be successful, even if your submission contains an error. The two exceptions when these tasks might fail due to your changes are: (1) if neptun.txt is missing, or (2) your C# code does not compile. The neptun.txt is mandatory, and no evaluation is performed until that is provided. The C# compilation is a step that must succeed; otherwise, your application cannot be started. There might be transient errors in these workflows. An example is when a download, such as the download of the .NET environment fails. The workflow execution can be repeated if this occurs. Retrying the execution may only help if the problem is indeed transient; a retry will not resolve a C# compilation error. (You can deduce the cause from the name of the step and the error message.) You might also be able to access the application logs. E.g., when testing a .NET application, it is started, and the logs will be printed here. The image below shows the initialization of an Entity Framework application, where you can also see the translated and executed SQL commands. (You would see the same in Visual Studio Output while debugging.) The content here, obviously, depends on the actual exercise.","title":"Using GitHub Actions"},{"location":"GitHub-credentials/","text":"In university laboratories: GitHub access \u00b6 The computers may remember the GitHub credentials. You should delete this at the end of the lab. Open Credential Manager from the Start menu. On the page Windows Credentials find the entry for GitHub and delete it.","title":"In university laboratories: GitHub access"},{"location":"GitHub-credentials/#in-university-laboratories-github-access","text":"The computers may remember the GitHub credentials. You should delete this at the end of the lab. Open Credential Manager from the Start menu. On the page Windows Credentials find the entry for GitHub and delete it.","title":"In university laboratories: GitHub access"},{"location":"GitHub/","text":"Submitting your work (GitHub) \u00b6 We are using GitHub to submit the solutions. Each laboratory is submitted in a GitHub repository that you will create through a provided link. The solution of the laboratory exercises is created within these repositories, then committed and pushed to GitHub. The submission is finished with a pull request assigned to the laboratory instructor with GitHub name mradazzouz . IMPORTANT The submission requirements detailed below are mandatory. Submissions not following these guidelines are not graded. Short version, aka. TL;DR \u00b6 The detailed description below shows the entire procedure. This summary is an overview of the whole process. The lab exercises are solved in a dedicated GitHub repository created using a GitHub Classroom invitation link published in Moodle. Your solution is submitted on a new branch, not on master. You can create any number of commits on this branch. You need to push these commits to GitHub. You submit your final solution through a pull request assigned to the laboratory instructor. You can ask questions regarding the results and evaluation in the pull request comment thread. To notify your instructor use the @name annotation in the comment text. Starting your work: git checkout \u00b6 Register a GitHub account if you don't have one yet. Open the course page in Moodle and find the invitation URL. This link is different for each lab; make sure to use the right one. If needed, authorize the GitHub Classroom application to use your account data. (This page will be displayed the first time you click the link in the previous step.) You will see a page where you can \"Accept the ... assignment\". Click the button. Wait for the repository creation to finish. You will get the repository URL here. Note The repository will be private. No one but you and the instructors will see it. Open the repository webpage by following the link. You will need this URL, so remember it. Clone your repository. You will need the repository git URL, which you can get from the repository webpage following the Clone or download button. You may use any git client. The simplest one is GitHub Desktop if you do not have a favorite yet. You can list your repositories in this application directly from GitHub. If you are using the console or shell, the following command performs the clone (if the git command is available): git clone <repository link> If the cloning is successful, DO NOT START WORKING YET! The solution should not be committed to the repository master branch. Instead, create a new branch with the name solution . In GitHub Desktop, use the Branch menu for creating a new one. If using the console, use the following command: git checkout -b solution Complete the exercises on this branch. You may have any number of commits and pushes. In university laboratories Before you make your first commit, check whether your name and email address are properly configured. You can check this using the following commands. git config user.name git config user.email If the values are not correct, set your name and email address with the following commands executed in the repository directory. This will set the values for the repository. (It is recommended to set the email address to the one you use with GitHub.) git config user.name \"John Doe\" git config user.email \"john@doe.org\" At home When working from home, you may want to set the name and email address globally using the --global switch in the commands above. To commit using GitHub Desktop, first check if you are on the correct branch. During the first push, the solution branch needs to be published. When adding further commits, verify the branch. You can publish the commit using the Push origin button. The tiny number on this button shows you how many commits need pushing. If you are using the console, use the following commands: # Check the current branch and the files modified git status # Prepares all changes for commit git add . # Commit git commit -m \"f1\" # Push the new branch (first time) git push --set-upstream origin solution # Push further commits git push Submitting the solution \u00b6 When you are ready with the exercises, verify on the repository web page that you uploaded everything. You may need to switch branches. GitHub web file upload We recommend that you do not use the GitHub web file upload. If something is missing, add it to your local repository and commit and push again. When you are truly ready, open a pull request . Why the pull request? This pull request combines all changes you made and shows us the final result. This helps the laboratory instructor to evaluate your submission more easily. This pull request means you submit your solution; hence this step cannot be omitted . To open the pull request , you need to go to the repository's GitHub web frontend. If you pushed recently, GitHub offers you to create the pull request. You may also open the pull request from the menu at the top. It is important to specify the correct branches: master is the target into which solution is merged. When the pull request is created, you will see a little number \"1\" on the Pull request menu showing you that there is one open item there. YOU ARE NOT FINISHED YET! The pull request will trigger a preliminary evaluation. You will see the result of this evaluation as a comment added to the pull request thread. This will be different for each laboratory. You will see the result in a comment in the pull request thread. If you need more information about the evaluation and the results, GitHub Actions can provide you more. A short introduction is provided here . If you are not satisfied with your work, you can make further changes. You only need to commit and push your changes. Any changes pushed will re-trigger the evaluation of the pull request . We ask that you trigger NO MORE THAN 5 evaluations ! Making further changes without running the evaluation If you want to make changes to your submission and not have the re-evaluation run, you should convert the pull request to draft . This state means work in progress. You can commit and push freely. These will not trigger any evaluation. Once ready, you must change the state back: go to the bottom of the PR and click \"Ready for review.\" This will set the PR back to its normal state and trigger an automated evaluation. Maximum 5 Evaluations that fail due to transient errors, such as network problems, are not counted into the 5 evaluations. But if you trigger more evaluation by mistake or on purpose, it will be sanctioned. You are required to test your solution locally before submitting it. FINALLY , when you are ready, assign the pull request to your laboratory instructor. This step is considered as the submission of your work. Without pull request If you have no pull request, or it is not assigned to the instructor, we consider it work in progress and not submitted. Done Now you are ready. After assigning the pull request, make no further changes . The instructor will evaluate the submission and close the pull request. Questions and complaints regarding the final result \u00b6 If you have questions or concerns regarding the automated evaluation, use the pull request for communication with the instructor by asking questions via comments. To let the instructor know you have questions, please use @mradazzouz mention in the PR comment. This will automatically send an email notification. Please provide proof Please note that if you think the evaluation made a mistake, you must support your question/complaint with proof (e.g., show how you tested your solution and prove that it worked).","title":"Submitting your work (GitHub)"},{"location":"GitHub/#submitting-your-work-github","text":"We are using GitHub to submit the solutions. Each laboratory is submitted in a GitHub repository that you will create through a provided link. The solution of the laboratory exercises is created within these repositories, then committed and pushed to GitHub. The submission is finished with a pull request assigned to the laboratory instructor with GitHub name mradazzouz . IMPORTANT The submission requirements detailed below are mandatory. Submissions not following these guidelines are not graded.","title":"Submitting your work (GitHub)"},{"location":"GitHub/#short-version-aka-tldr","text":"The detailed description below shows the entire procedure. This summary is an overview of the whole process. The lab exercises are solved in a dedicated GitHub repository created using a GitHub Classroom invitation link published in Moodle. Your solution is submitted on a new branch, not on master. You can create any number of commits on this branch. You need to push these commits to GitHub. You submit your final solution through a pull request assigned to the laboratory instructor. You can ask questions regarding the results and evaluation in the pull request comment thread. To notify your instructor use the @name annotation in the comment text.","title":"Short version, aka. TL;DR"},{"location":"GitHub/#starting-your-work-git-checkout","text":"Register a GitHub account if you don't have one yet. Open the course page in Moodle and find the invitation URL. This link is different for each lab; make sure to use the right one. If needed, authorize the GitHub Classroom application to use your account data. (This page will be displayed the first time you click the link in the previous step.) You will see a page where you can \"Accept the ... assignment\". Click the button. Wait for the repository creation to finish. You will get the repository URL here. Note The repository will be private. No one but you and the instructors will see it. Open the repository webpage by following the link. You will need this URL, so remember it. Clone your repository. You will need the repository git URL, which you can get from the repository webpage following the Clone or download button. You may use any git client. The simplest one is GitHub Desktop if you do not have a favorite yet. You can list your repositories in this application directly from GitHub. If you are using the console or shell, the following command performs the clone (if the git command is available): git clone <repository link> If the cloning is successful, DO NOT START WORKING YET! The solution should not be committed to the repository master branch. Instead, create a new branch with the name solution . In GitHub Desktop, use the Branch menu for creating a new one. If using the console, use the following command: git checkout -b solution Complete the exercises on this branch. You may have any number of commits and pushes. In university laboratories Before you make your first commit, check whether your name and email address are properly configured. You can check this using the following commands. git config user.name git config user.email If the values are not correct, set your name and email address with the following commands executed in the repository directory. This will set the values for the repository. (It is recommended to set the email address to the one you use with GitHub.) git config user.name \"John Doe\" git config user.email \"john@doe.org\" At home When working from home, you may want to set the name and email address globally using the --global switch in the commands above. To commit using GitHub Desktop, first check if you are on the correct branch. During the first push, the solution branch needs to be published. When adding further commits, verify the branch. You can publish the commit using the Push origin button. The tiny number on this button shows you how many commits need pushing. If you are using the console, use the following commands: # Check the current branch and the files modified git status # Prepares all changes for commit git add . # Commit git commit -m \"f1\" # Push the new branch (first time) git push --set-upstream origin solution # Push further commits git push","title":"Starting your work: git checkout"},{"location":"GitHub/#submitting-the-solution","text":"When you are ready with the exercises, verify on the repository web page that you uploaded everything. You may need to switch branches. GitHub web file upload We recommend that you do not use the GitHub web file upload. If something is missing, add it to your local repository and commit and push again. When you are truly ready, open a pull request . Why the pull request? This pull request combines all changes you made and shows us the final result. This helps the laboratory instructor to evaluate your submission more easily. This pull request means you submit your solution; hence this step cannot be omitted . To open the pull request , you need to go to the repository's GitHub web frontend. If you pushed recently, GitHub offers you to create the pull request. You may also open the pull request from the menu at the top. It is important to specify the correct branches: master is the target into which solution is merged. When the pull request is created, you will see a little number \"1\" on the Pull request menu showing you that there is one open item there. YOU ARE NOT FINISHED YET! The pull request will trigger a preliminary evaluation. You will see the result of this evaluation as a comment added to the pull request thread. This will be different for each laboratory. You will see the result in a comment in the pull request thread. If you need more information about the evaluation and the results, GitHub Actions can provide you more. A short introduction is provided here . If you are not satisfied with your work, you can make further changes. You only need to commit and push your changes. Any changes pushed will re-trigger the evaluation of the pull request . We ask that you trigger NO MORE THAN 5 evaluations ! Making further changes without running the evaluation If you want to make changes to your submission and not have the re-evaluation run, you should convert the pull request to draft . This state means work in progress. You can commit and push freely. These will not trigger any evaluation. Once ready, you must change the state back: go to the bottom of the PR and click \"Ready for review.\" This will set the PR back to its normal state and trigger an automated evaluation. Maximum 5 Evaluations that fail due to transient errors, such as network problems, are not counted into the 5 evaluations. But if you trigger more evaluation by mistake or on purpose, it will be sanctioned. You are required to test your solution locally before submitting it. FINALLY , when you are ready, assign the pull request to your laboratory instructor. This step is considered as the submission of your work. Without pull request If you have no pull request, or it is not assigned to the instructor, we consider it work in progress and not submitted. Done Now you are ready. After assigning the pull request, make no further changes . The instructor will evaluate the submission and close the pull request.","title":"Submitting the solution"},{"location":"GitHub/#questions-and-complaints-regarding-the-final-result","text":"If you have questions or concerns regarding the automated evaluation, use the pull request for communication with the instructor by asking questions via comments. To let the instructor know you have questions, please use @mradazzouz mention in the PR comment. This will automatically send an email notification. Please provide proof Please note that if you think the evaluation made a mistake, you must support your question/complaint with proof (e.g., show how you tested your solution and prove that it worked).","title":"Questions and complaints regarding the final result"},{"location":"VisualStudio/","text":"Install Visual Studio & .NET Core SDK \u00b6 In some of the exercises require Microsoft Visual Studio version 2019 16.6 or newer . With the exception of one topic, VS version 2022 is fine too. The free Community edition is sufficient for solving these exercises. You can check the version by starting the Visual Studio Installer : VS Code The exercises can also be solved using the platform-independent Visual Studio Code . The skeletons of the exercises are prepared for Visual Studio. If you are working with VS Code, you need to configure your environment. Visual Studio workloads \u00b6 When installing Visual Studio, the following workloads have to be selected: ASP.NET and web development .NET Core cross-platform development An existing installation can be modified using the Visual Studio Installer . Check and install .NET Core SDK \u00b6 Visual Studio might install certain versions of the .NET Core SDK. To check if you have the right version, use the dotnet CLI: in a console, execute the dotnet --list-sdks command. This command works on Linux and Mac too. It will print something similar: C:\\>dotnet --list-sdks 3.1.404 [C:\\Program Files\\dotnet\\sdk] 5.0.101 [C:\\Program Files\\dotnet\\sdk] If you see version 3.1 in this list, then you are good to go. Otherwise, install the SDK from here .","title":"Install Visual Studio & .NET Core SDK"},{"location":"VisualStudio/#install-visual-studio-net-core-sdk","text":"In some of the exercises require Microsoft Visual Studio version 2019 16.6 or newer . With the exception of one topic, VS version 2022 is fine too. The free Community edition is sufficient for solving these exercises. You can check the version by starting the Visual Studio Installer : VS Code The exercises can also be solved using the platform-independent Visual Studio Code . The skeletons of the exercises are prepared for Visual Studio. If you are working with VS Code, you need to configure your environment.","title":"Install Visual Studio &amp; .NET Core SDK"},{"location":"VisualStudio/#visual-studio-workloads","text":"When installing Visual Studio, the following workloads have to be selected: ASP.NET and web development .NET Core cross-platform development An existing installation can be modified using the Visual Studio Installer .","title":"Visual Studio workloads"},{"location":"VisualStudio/#check-and-install-net-core-sdk","text":"Visual Studio might install certain versions of the .NET Core SDK. To check if you have the right version, use the dotnet CLI: in a console, execute the dotnet --list-sdks command. This command works on Linux and Mac too. It will print something similar: C:\\>dotnet --list-sdks 3.1.404 [C:\\Program Files\\dotnet\\sdk] 5.0.101 [C:\\Program Files\\dotnet\\sdk] If you see version 3.1 in this list, then you are good to go. Otherwise, install the SDK from here .","title":"Check and install .NET Core SDK"},{"location":"Lab-EFREST/","text":"Entity Framework and REST \u00b6 We will build a new REST API (ASP.NET Core Web API) using Entity Framework. Pre-requisites and preparation \u00b6 Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. Postman DB Browser for SQLite - if you would like to check the database (not necessary) GitHub account and a git client Microsoft Visual Studio 2019/2022 with the settings here When using Linux or macOS, you can use Visual Studio Code, the .NET Core SDK, and dotnet CLI . .NET Core 3.1 SDK .NET Core 3.1 Mind the version! You need .NET Core SDK version 3.1 to solve these exercises. On Windows, it might already be installed along with Visual Studio (see here how to check it); if not, use the link above to install (the SDK and not the runtime). You need to install it manually when using Linux or macOS. Materials for preparing for this laboratory: Entity Framework, REST API, Web API, and using Postman Check the materials of Data-driven systems including the seminars Official Microsoft tutorial for Web API Exercise overview \u00b6 In this exercise, we will implement the backend of a simple task management web application. The application handles two types of entities: statuses and tasks where a status is associated with multiple tasks (1-* connection). (In the text of the exercises, will use tasks only for referring to this entity of the application.) If we had a frontend, the application would be a Kanban-board . We will not create a frontend here, only the REST API and Entity Framework + ASP.NET Core Web API server. Initial steps \u00b6 Keep in mind that you are expected to follow the submission process . Create and check out your Git repository \u00b6 Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file. Creating the database \u00b6 We will not be using Microsoft SQL Server here, but Sqlite . It is a light-weight relational database management system mainly for client-side applications. Although it is not recommended for servers, we will use it for simplicity. Sqlite requires no installation. We will define the database schema with code first using C# code. Therefore, we will not need to create the schema with SQL commands.","title":"Entity Framework and REST"},{"location":"Lab-EFREST/#entity-framework-and-rest","text":"We will build a new REST API (ASP.NET Core Web API) using Entity Framework.","title":"Entity Framework and REST"},{"location":"Lab-EFREST/#pre-requisites-and-preparation","text":"Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. Postman DB Browser for SQLite - if you would like to check the database (not necessary) GitHub account and a git client Microsoft Visual Studio 2019/2022 with the settings here When using Linux or macOS, you can use Visual Studio Code, the .NET Core SDK, and dotnet CLI . .NET Core 3.1 SDK .NET Core 3.1 Mind the version! You need .NET Core SDK version 3.1 to solve these exercises. On Windows, it might already be installed along with Visual Studio (see here how to check it); if not, use the link above to install (the SDK and not the runtime). You need to install it manually when using Linux or macOS. Materials for preparing for this laboratory: Entity Framework, REST API, Web API, and using Postman Check the materials of Data-driven systems including the seminars Official Microsoft tutorial for Web API","title":"Pre-requisites and preparation"},{"location":"Lab-EFREST/#exercise-overview","text":"In this exercise, we will implement the backend of a simple task management web application. The application handles two types of entities: statuses and tasks where a status is associated with multiple tasks (1-* connection). (In the text of the exercises, will use tasks only for referring to this entity of the application.) If we had a frontend, the application would be a Kanban-board . We will not create a frontend here, only the REST API and Entity Framework + ASP.NET Core Web API server.","title":"Exercise overview"},{"location":"Lab-EFREST/#initial-steps","text":"Keep in mind that you are expected to follow the submission process .","title":"Initial steps"},{"location":"Lab-EFREST/#create-and-check-out-your-git-repository","text":"Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file.","title":"Create and check out your Git repository"},{"location":"Lab-EFREST/#creating-the-database","text":"We will not be using Microsoft SQL Server here, but Sqlite . It is a light-weight relational database management system mainly for client-side applications. Although it is not recommended for servers, we will use it for simplicity. Sqlite requires no installation. We will define the database schema with code first using C# code. Therefore, we will not need to create the schema with SQL commands.","title":"Creating the database"},{"location":"Lab-EFREST/Exercise-1/","text":"Exercise 1: Managing statuses \u00b6 In this exercise, we will implement the basic management of status entities. You can earn 8 points with the completion of this exercise. Open the Visual Studio solution \u00b6 Open the Visual Studio solution (the .sln ) file in the checked-out repository. If Visual Studio tells you that the project is not supported, you need to install a missing component (see here ). Do NOT upgrade any version Do not upgrade the project, the .NET Core version, or any Nuget package! If you see such a question, always choose no! The solution is structured according to a multi-tier architecture: The Controllers folder has the Web Api controllers handling the REST requests. The DAL folder implements the data access; it contains a repository layer and an Entity Framework Code First data model. The Model folder contains the shared entities. In this exercise, you will need to work in classes DAL.StatusesRepository and Controllers.StatusesController . You can make changes to these classes as long as the source code complies (and the repository implements interface IStatusesRepository ). Start the web app \u00b6 Check if the web application starts. Compile the code and start in Visual Studio. Open URL http://localhost:5000/api/ping in a browser. If everything goes well, you see the response \"pong\" in the browser, and the incoming request is logged in the console. List all statuses (4p) \u00b6 Implement the first operation to list all available status entities. Open class Model.Status . This is the entity class used by the business layer. Do NOT make any changes to this class. Open class DAL.EfDbContext.DbStatus . This is the Entity Framework and database representation of the same entity. Let us implement this class: public class DbStatus { public int Id { get ; set ; } public string Name { get ; set ; } } The Id is the primary key in the database, and Name is the name of the status. Open class DAL.EfDbContext.TasksDbContext . We need to add a new DbSet property here and configure the C# - database mapping in method OnModelCreating : public class TasksDbContext : DbContext { public DbSet < DbStatus > Statuses { get ; set ; } protected override void OnModelCreating ( ModelBuilder modelBuilder ) { modelBuilder . Entity < DbStatus >() . ToTable ( \"statuses\" ); modelBuilder . Entity < DbStatus >() . HasKey ( s => s . Id ); modelBuilder . Entity < DbStatus >() . Property ( s => s . Name ). HasMaxLength ( 50 ) . IsRequired ( required : true ). IsUnicode ( unicode : true ); } } This configuration sets the name of the table in the database, the key (which will generate values automatically), and the constraints related to the name field. Go to the method DAL.StatusesRepository.List() . This is the repository layer that interacts with the database using Entity Framework. Let us list all statuses from the database: public IReadOnlyCollection < Model . Status > List () { return db . Statuses . Select ( ToModel ). ToList (); } The variable db represents our database, the DbContext, injected via the framework. We will use the helper method ToModel to translate the EF representation to the business layer representation. Let us implement this method (in the repository class). private static Model . Status ToModel ( DbStatus value ) { return new Model . Status ( value . Id , value . Name ); } Once the repository is ready, let us move to the controller. Open class Controllers.StatusesController . Add your Neptun code into the controller's URL : this controller shall respond to queries that arrive at URL /api/statuses/neptun where the last 6 characters are your Neptun code, all lowercase. [Route(\"api/statuses/neptun\")] [ApiController] public class StatusesController : ControllerBase Neptun code is important The Neptun code shall appear in screenshots later. You must add it as specified above! Let us implement an endpoint for handling the GET /api/statuses/neptun request: The dependency injection is configured already; thus, the constructor accepts the repository interface ( not the implementation but its interface). public class StatusesController : ControllerBase { // ... [HttpGet] public IEnumerable < Status > List () { return repository . List (); } } Compile the code and start the app. Open Postman and send a GET request to URL http://localhost:5000/api/statuses/neptun (with your Neptun code in the URL). The query is successful if Postman reports status code 200, and the result is empty. If there is an error, check the Output window in Visual Studio and the running application console window. Add some test data. Stop the application. Go to method DAL.EfDbContext.TasksDbContext.OnModelCreating and insert a few test records (also called seed data ): public class TasksDbContext : DbContext { protected override void OnModelCreating ( ModelBuilder modelBuilder ) { // ... modelBuilder . Entity < DbStatus >() . HasData ( new [] { new DbStatus () { Id = 1 , Name = \"new\" }, new DbStatus () { Id = 2 , Name = \"in progress\" }, }); } } Compile the code again, then start the application and repeat the same GET query. The response shall include the two statuses. If you do not see the status records If the seed records do not appear in the response, it is possible that the database was not updated with the HasData method. Delete the SQLite database file tasks.db ; this will re-create the database when the application starts again. Generally, schema and data modification in live environments are handled using migrations . To simplify things, we will not use migrations. If the database schema is changed, delete tasks.db . Query and insert operations (4p) \u00b6 There are a few other operations we need to implement: check existence by specifying name ( HEAD /api/statuses/neptun/{name} ), find record by ID ( GET /api/statuses/neptun/{id} ), adding a new status record ( POST /api/statuses/neptun ). Let us implement these. Let us start with the implementation of the first two in the repository. When looking for an item based on a name, we will perform a case-insensitive comparison. public bool ExistsWithName ( string statusName ) { return db . Statuses . Any ( s => EF . Functions . Like ( s . Name , statusName )); } public Model . Status FindById ( int statusId ) { var dbRecord = db . Statuses . FirstOrDefault ( s => s . Id == statusId ); if ( dbRecord == null ) return null ; else return ToModel ( dbRecord ); } EF.Functions.Like helps us to write a SQL like query in Entity Framework. The command will translate into the proper LIKE operator when executed, allowing us to perform a case insensitive comparison. The controller endpoints for these operations are: [HttpHead(\"{statusName}\")] [ProducesResponseType(StatusCodes.Status200OK)] [ProducesResponseType(StatusCodes.Status404NotFound)] public ActionResult ExistsWithName ( string statusName ) { var exists = repository . ExistsWithName ( statusName ); if ( exists ) return Ok (); else return NotFound (); } [HttpGet(\"{id}\")] [ProducesResponseType(StatusCodes.Status200OK)] [ProducesResponseType(StatusCodes.Status404NotFound)] public ActionResult < Status > Get ( int id ) { var value = repository . FindById ( id ); if ( value == null ) return NotFound (); else return Ok ( value ); } Note the controller method attributes and return values! If the response contains data (in the http body, the return type is ActionResult<T> ; if there is no body and only a status code is returned, the return type is ActionResult . Methods Ok and NotFound help us create the correct responses. The URL is defined on two \"levels.\" We defined /api/statuses/neptun on the controller; it applies to all endpoints. It is the \"last part\" of the URL that is defined on each endpoint separately. To implement the insertion, let us start with the repository again. Insert is triggered by receiving a CreateStatus model class with a name. We want to ensure unique names. Thus, we need to verify it before insertion. public Model . Status Insert ( CreateStatus value ) { using ( var tran = db . Database . BeginTransaction ( System . Data . IsolationLevel . RepeatableRead )) { if ( db . Statuses . Any ( s => EF . Functions . Like ( s . Name , value . Name ))) throw new ArgumentException ( \"name must be unique\" ); var toInsert = new DbStatus () { Name = value . Name }; db . Statuses . Add ( toInsert ); db . SaveChanges (); tran . Commit (); return new Model . Status ( toInsert . Id , toInsert . Name ); } } Mind the transaction! First, we check if an identical name exists. If so, an error is raised. After inserting the record, the transaction also has to be committed. Since the database assigns the ID, the repository needs to return the created entity with this assigned ID. The POST http request is handled by the following controller endpoint: [HttpPost] [ProducesResponseType(StatusCodes.Status201Created)] [ProducesResponseType(StatusCodes.Status400BadRequest)] public ActionResult < Status > Create ([ FromBody ] Dto . CreateStatus value ) { try { var created = repository . Insert ( value ); return CreatedAtAction ( nameof ( Get ), new { id = created . Id }, created ); } catch ( ArgumentException ex ) { return BadRequest ( new { error = ex . Message }); } } Note both the successful and the failed responses. If insertion succeeded, the CreatedAtAction helper method prepares a response that contains the entity in the body and adds a Location header with the URL to fetch the record (thus the reference to nameof(Get) ). In case of failure, the exception is handled by reporting the error to the caller. The status code will be 400, and the body will indicate an explanation as text (as REST does not have other means to report errors besides status code). Compile and start the app. Test the queries! Produce both successful and erroneous responses too. SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows a failed insert request and response. The cause of failure should be that an item with the same name already exists. Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Exercise 1: Managing statuses"},{"location":"Lab-EFREST/Exercise-1/#exercise-1-managing-statuses","text":"In this exercise, we will implement the basic management of status entities. You can earn 8 points with the completion of this exercise.","title":"Exercise 1: Managing statuses"},{"location":"Lab-EFREST/Exercise-1/#open-the-visual-studio-solution","text":"Open the Visual Studio solution (the .sln ) file in the checked-out repository. If Visual Studio tells you that the project is not supported, you need to install a missing component (see here ). Do NOT upgrade any version Do not upgrade the project, the .NET Core version, or any Nuget package! If you see such a question, always choose no! The solution is structured according to a multi-tier architecture: The Controllers folder has the Web Api controllers handling the REST requests. The DAL folder implements the data access; it contains a repository layer and an Entity Framework Code First data model. The Model folder contains the shared entities. In this exercise, you will need to work in classes DAL.StatusesRepository and Controllers.StatusesController . You can make changes to these classes as long as the source code complies (and the repository implements interface IStatusesRepository ).","title":"Open the Visual Studio solution"},{"location":"Lab-EFREST/Exercise-1/#start-the-web-app","text":"Check if the web application starts. Compile the code and start in Visual Studio. Open URL http://localhost:5000/api/ping in a browser. If everything goes well, you see the response \"pong\" in the browser, and the incoming request is logged in the console.","title":"Start the web app"},{"location":"Lab-EFREST/Exercise-1/#list-all-statuses-4p","text":"Implement the first operation to list all available status entities. Open class Model.Status . This is the entity class used by the business layer. Do NOT make any changes to this class. Open class DAL.EfDbContext.DbStatus . This is the Entity Framework and database representation of the same entity. Let us implement this class: public class DbStatus { public int Id { get ; set ; } public string Name { get ; set ; } } The Id is the primary key in the database, and Name is the name of the status. Open class DAL.EfDbContext.TasksDbContext . We need to add a new DbSet property here and configure the C# - database mapping in method OnModelCreating : public class TasksDbContext : DbContext { public DbSet < DbStatus > Statuses { get ; set ; } protected override void OnModelCreating ( ModelBuilder modelBuilder ) { modelBuilder . Entity < DbStatus >() . ToTable ( \"statuses\" ); modelBuilder . Entity < DbStatus >() . HasKey ( s => s . Id ); modelBuilder . Entity < DbStatus >() . Property ( s => s . Name ). HasMaxLength ( 50 ) . IsRequired ( required : true ). IsUnicode ( unicode : true ); } } This configuration sets the name of the table in the database, the key (which will generate values automatically), and the constraints related to the name field. Go to the method DAL.StatusesRepository.List() . This is the repository layer that interacts with the database using Entity Framework. Let us list all statuses from the database: public IReadOnlyCollection < Model . Status > List () { return db . Statuses . Select ( ToModel ). ToList (); } The variable db represents our database, the DbContext, injected via the framework. We will use the helper method ToModel to translate the EF representation to the business layer representation. Let us implement this method (in the repository class). private static Model . Status ToModel ( DbStatus value ) { return new Model . Status ( value . Id , value . Name ); } Once the repository is ready, let us move to the controller. Open class Controllers.StatusesController . Add your Neptun code into the controller's URL : this controller shall respond to queries that arrive at URL /api/statuses/neptun where the last 6 characters are your Neptun code, all lowercase. [Route(\"api/statuses/neptun\")] [ApiController] public class StatusesController : ControllerBase Neptun code is important The Neptun code shall appear in screenshots later. You must add it as specified above! Let us implement an endpoint for handling the GET /api/statuses/neptun request: The dependency injection is configured already; thus, the constructor accepts the repository interface ( not the implementation but its interface). public class StatusesController : ControllerBase { // ... [HttpGet] public IEnumerable < Status > List () { return repository . List (); } } Compile the code and start the app. Open Postman and send a GET request to URL http://localhost:5000/api/statuses/neptun (with your Neptun code in the URL). The query is successful if Postman reports status code 200, and the result is empty. If there is an error, check the Output window in Visual Studio and the running application console window. Add some test data. Stop the application. Go to method DAL.EfDbContext.TasksDbContext.OnModelCreating and insert a few test records (also called seed data ): public class TasksDbContext : DbContext { protected override void OnModelCreating ( ModelBuilder modelBuilder ) { // ... modelBuilder . Entity < DbStatus >() . HasData ( new [] { new DbStatus () { Id = 1 , Name = \"new\" }, new DbStatus () { Id = 2 , Name = \"in progress\" }, }); } } Compile the code again, then start the application and repeat the same GET query. The response shall include the two statuses. If you do not see the status records If the seed records do not appear in the response, it is possible that the database was not updated with the HasData method. Delete the SQLite database file tasks.db ; this will re-create the database when the application starts again. Generally, schema and data modification in live environments are handled using migrations . To simplify things, we will not use migrations. If the database schema is changed, delete tasks.db .","title":"List all statuses (4p)"},{"location":"Lab-EFREST/Exercise-1/#query-and-insert-operations-4p","text":"There are a few other operations we need to implement: check existence by specifying name ( HEAD /api/statuses/neptun/{name} ), find record by ID ( GET /api/statuses/neptun/{id} ), adding a new status record ( POST /api/statuses/neptun ). Let us implement these. Let us start with the implementation of the first two in the repository. When looking for an item based on a name, we will perform a case-insensitive comparison. public bool ExistsWithName ( string statusName ) { return db . Statuses . Any ( s => EF . Functions . Like ( s . Name , statusName )); } public Model . Status FindById ( int statusId ) { var dbRecord = db . Statuses . FirstOrDefault ( s => s . Id == statusId ); if ( dbRecord == null ) return null ; else return ToModel ( dbRecord ); } EF.Functions.Like helps us to write a SQL like query in Entity Framework. The command will translate into the proper LIKE operator when executed, allowing us to perform a case insensitive comparison. The controller endpoints for these operations are: [HttpHead(\"{statusName}\")] [ProducesResponseType(StatusCodes.Status200OK)] [ProducesResponseType(StatusCodes.Status404NotFound)] public ActionResult ExistsWithName ( string statusName ) { var exists = repository . ExistsWithName ( statusName ); if ( exists ) return Ok (); else return NotFound (); } [HttpGet(\"{id}\")] [ProducesResponseType(StatusCodes.Status200OK)] [ProducesResponseType(StatusCodes.Status404NotFound)] public ActionResult < Status > Get ( int id ) { var value = repository . FindById ( id ); if ( value == null ) return NotFound (); else return Ok ( value ); } Note the controller method attributes and return values! If the response contains data (in the http body, the return type is ActionResult<T> ; if there is no body and only a status code is returned, the return type is ActionResult . Methods Ok and NotFound help us create the correct responses. The URL is defined on two \"levels.\" We defined /api/statuses/neptun on the controller; it applies to all endpoints. It is the \"last part\" of the URL that is defined on each endpoint separately. To implement the insertion, let us start with the repository again. Insert is triggered by receiving a CreateStatus model class with a name. We want to ensure unique names. Thus, we need to verify it before insertion. public Model . Status Insert ( CreateStatus value ) { using ( var tran = db . Database . BeginTransaction ( System . Data . IsolationLevel . RepeatableRead )) { if ( db . Statuses . Any ( s => EF . Functions . Like ( s . Name , value . Name ))) throw new ArgumentException ( \"name must be unique\" ); var toInsert = new DbStatus () { Name = value . Name }; db . Statuses . Add ( toInsert ); db . SaveChanges (); tran . Commit (); return new Model . Status ( toInsert . Id , toInsert . Name ); } } Mind the transaction! First, we check if an identical name exists. If so, an error is raised. After inserting the record, the transaction also has to be committed. Since the database assigns the ID, the repository needs to return the created entity with this assigned ID. The POST http request is handled by the following controller endpoint: [HttpPost] [ProducesResponseType(StatusCodes.Status201Created)] [ProducesResponseType(StatusCodes.Status400BadRequest)] public ActionResult < Status > Create ([ FromBody ] Dto . CreateStatus value ) { try { var created = repository . Insert ( value ); return CreatedAtAction ( nameof ( Get ), new { id = created . Id }, created ); } catch ( ArgumentException ex ) { return BadRequest ( new { error = ex . Message }); } } Note both the successful and the failed responses. If insertion succeeded, the CreatedAtAction helper method prepares a response that contains the entity in the body and adds a Location header with the URL to fetch the record (thus the reference to nameof(Get) ). In case of failure, the exception is handled by reporting the error to the caller. The status code will be 400, and the body will indicate an explanation as text (as REST does not have other means to report errors besides status code). Compile and start the app. Test the queries! Produce both successful and erroneous responses too. SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows a failed insert request and response. The cause of failure should be that an item with the same name already exists. Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Query and insert operations (4p)"},{"location":"Lab-EFREST/Exercise-2/","text":"Exercise 2: Task operations \u00b6 In this exercise, we will implement the basic services for tasks . You can earn 6 points with the completion of this exercise. Preparation with Entity Framework \u00b6 The task entity is represented by the class Model.Task . It has a unique ID , a text Title , a Done flag to signal completion, and a Status field referencing the status of this task (with 1-* multiplicity). Define the Entity Framework model first: Define the Entity Framework data model of this entity in class DAL.EfDbContext.DbTask . The referenced status should be a proper navigation property ! Add the new DbSet field to class TasksDbContext . Specify the configuration of the mapping of this entity in OnModelCreating . Make sure to configure the navigation property here correctly! Add some initial (\"seed\") data, as seen previously. Operations in the repository \u00b6 Create a new class, TasksRepository , in the DAL folder that implements the existing ITasksRepository interface. Implement the following operations: IReadOnlyCollection<Task> List() : lists all available tasks Task FindById(int taskId) : returns the single task with the specified ID if it exists; returns null otherwise Task Insert(CreateTask value) : adds a new task to the database with the specified title and associates it with the specified status; if no status with the provided name exists, create a new status record; the return value is the new task entity as created in the database with its assigned ID Task Delete(int taskId) : deletes the specified task; return value is the task (state before deletion), or null if the task does not exist You don't need to implement the other operations yet; however, an implementation needs to be provided so that the code compiles. You may use throw new NotImplementedException(); as a placeholder for now. Tip You will need to map the database entity to the model class in the repository. It is recommended to create a ToModel helper method, as seen previously. When querying the tasks, you will need the associated status record too (to get the name). You will need to use an .Include() . Operations on the REST Api \u00b6 Create a new TasksController in the Controllers folder. The controller shall handle REST queries on URL /api/tasks/neptun where the last part is your own Neptun code lowercase. The controller shall take an ITasksRepository as a parameter. For the dependency injection framework to resolve this in runtime, further configuration is needed. In the Startup class, register this interface and its corresponding implementation in the method ConfigureServices similarly to how the other repository is registered. (The controller does not need registration.) Implement the following operations using the previously implemented repository methods: GET /api/tasks/neptun : returns all tasks; response code is always 200 OK GET /api/tasks/neptun/{id} : gets a single task; response code is 200 OK or 404 Not found POST /api/tasks/neptun : add a new task based on a Dto.CreateTask instance specified in the body; the response code is 201 Created with the new entity in the body and an appropriate Location header DELETE /api/tasks/neptun/{id} : deleted a task; response code is 204 No content or 404 Not found SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows an arbitrary request and response from the list above. Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Exercise 2: Task operations"},{"location":"Lab-EFREST/Exercise-2/#exercise-2-task-operations","text":"In this exercise, we will implement the basic services for tasks . You can earn 6 points with the completion of this exercise.","title":"Exercise 2: Task operations"},{"location":"Lab-EFREST/Exercise-2/#preparation-with-entity-framework","text":"The task entity is represented by the class Model.Task . It has a unique ID , a text Title , a Done flag to signal completion, and a Status field referencing the status of this task (with 1-* multiplicity). Define the Entity Framework model first: Define the Entity Framework data model of this entity in class DAL.EfDbContext.DbTask . The referenced status should be a proper navigation property ! Add the new DbSet field to class TasksDbContext . Specify the configuration of the mapping of this entity in OnModelCreating . Make sure to configure the navigation property here correctly! Add some initial (\"seed\") data, as seen previously.","title":"Preparation with Entity Framework"},{"location":"Lab-EFREST/Exercise-2/#operations-in-the-repository","text":"Create a new class, TasksRepository , in the DAL folder that implements the existing ITasksRepository interface. Implement the following operations: IReadOnlyCollection<Task> List() : lists all available tasks Task FindById(int taskId) : returns the single task with the specified ID if it exists; returns null otherwise Task Insert(CreateTask value) : adds a new task to the database with the specified title and associates it with the specified status; if no status with the provided name exists, create a new status record; the return value is the new task entity as created in the database with its assigned ID Task Delete(int taskId) : deletes the specified task; return value is the task (state before deletion), or null if the task does not exist You don't need to implement the other operations yet; however, an implementation needs to be provided so that the code compiles. You may use throw new NotImplementedException(); as a placeholder for now. Tip You will need to map the database entity to the model class in the repository. It is recommended to create a ToModel helper method, as seen previously. When querying the tasks, you will need the associated status record too (to get the name). You will need to use an .Include() .","title":"Operations in the repository"},{"location":"Lab-EFREST/Exercise-2/#operations-on-the-rest-api","text":"Create a new TasksController in the Controllers folder. The controller shall handle REST queries on URL /api/tasks/neptun where the last part is your own Neptun code lowercase. The controller shall take an ITasksRepository as a parameter. For the dependency injection framework to resolve this in runtime, further configuration is needed. In the Startup class, register this interface and its corresponding implementation in the method ConfigureServices similarly to how the other repository is registered. (The controller does not need registration.) Implement the following operations using the previously implemented repository methods: GET /api/tasks/neptun : returns all tasks; response code is always 200 OK GET /api/tasks/neptun/{id} : gets a single task; response code is 200 OK or 404 Not found POST /api/tasks/neptun : add a new task based on a Dto.CreateTask instance specified in the body; the response code is 201 Created with the new entity in the body and an appropriate Location header DELETE /api/tasks/neptun/{id} : deleted a task; response code is 204 No content or 404 Not found SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows an arbitrary request and response from the list above. Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Operations on the REST Api"},{"location":"Lab-EFREST/Exercise-3/","text":"Exercise 3: Task operations \u00b6 Implement two new endpoints in the controller handling tasks that alter existing tasks as follows. You can earn 3-3 points with the completion of these exercises. Marking a task as done \u00b6 The flag Task.Done signals that a task is completed. Create a new http endpoint that uses the ITasksRepository.MarkDone method to set this flag on a task instance. Request: PATCH /api/tasks/neptun/{id}/done with {id} being the tasks ID. Response: 404 Not found if no such task exists. 200 OK if the operation was successful - returns the task in the body after the modification is done. Move to a new status \u00b6 A task is associated with status through Task.StatusId (or similar). Create a new http endpoint that uses the ITasksRepository.MoveToStatus method to change the status of the specified tasks to a new one. If the new status with the provided name does not exist, create one. Request: PATCH /api/tasks/neptun/{id}/move?newStatusName=newname with {id} is the task's ID, and the name of the new status is received in the newStatusName query parameter. Response: 404 Not found if no such task exists. 200 OK if the operation was successful - returns the task in the body after the modification is done. SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows an arbitrary request and response from the two above. Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Exercise 3: Task operations"},{"location":"Lab-EFREST/Exercise-3/#exercise-3-task-operations","text":"Implement two new endpoints in the controller handling tasks that alter existing tasks as follows. You can earn 3-3 points with the completion of these exercises.","title":"Exercise 3: Task operations"},{"location":"Lab-EFREST/Exercise-3/#marking-a-task-as-done","text":"The flag Task.Done signals that a task is completed. Create a new http endpoint that uses the ITasksRepository.MarkDone method to set this flag on a task instance. Request: PATCH /api/tasks/neptun/{id}/done with {id} being the tasks ID. Response: 404 Not found if no such task exists. 200 OK if the operation was successful - returns the task in the body after the modification is done.","title":"Marking a task as done"},{"location":"Lab-EFREST/Exercise-3/#move-to-a-new-status","text":"A task is associated with status through Task.StatusId (or similar). Create a new http endpoint that uses the ITasksRepository.MoveToStatus method to change the status of the specified tasks to a new one. If the new status with the provided name does not exist, create one. Request: PATCH /api/tasks/neptun/{id}/move?newStatusName=newname with {id} is the task's ID, and the name of the new status is received in the newStatusName query parameter. Response: 404 Not found if no such task exists. 200 OK if the operation was successful - returns the task in the body after the modification is done. SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows an arbitrary request and response from the two above. Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Move to a new status"},{"location":"Lab-EFREST/Exercise-4/","text":"Exercise 4: Optional exercise \u00b6 You can earn an additional +3 points with the completion of this exercise. (In the evaluation, you will see the text \"imsc\" in the exercise title; this is meant for the Hungarian students. Please ignore that.) If we have lots of tasks listing them should not return all of them at once. Implement a new endpoint to return a subset of the tasks (i.e., \"paging\"): It returns the tasks in a deterministic fashion sorted by ID. The query accepts a count parameter that specifies how many tasks to return. Specifying the next page is performed via a from parameter. This from is the ID of the first item to return on this page. Both the from and count are specified as query parameters. The new paging endpoint should be available on URL GET /api/tasks/neptun/paged (the /paged part is necessary so that the previous listing endpoint also remains functional). The response should return an instance of class Controllers.Dto.PagedTaskList . This includes: items : an array containing the tasks on the current page, count : specifying the number of items on the current page, nextId : id of the next task - to fetch the next page (to be used in from ), nextUrl : a helper URL that fetches the next page, or null if there are no further pages. Use the Url.Action helper method to assemble this URL. Do not hardcode \"localhost:5000\" or \"/api/tasks/paged\" in the source code! You will not need string operations to achieve this. Url.Action will give you an absolute URL when all parameters ( action , controller , values , protocol , and host ) are specified; for the latter ones this.HttpContext.Request can provide you the required values. The request always returns 200 OK; if there are no items, the result set shall be empty. The requests-responses shows you the expected behavior: GET /api/tasks/neptun/paged?count=2 This is the first request. There is no from value specified to start from the first item. Response: { \"items\" : [ { \"id\" : 1 , \"title\" : \"doing homework\" , \"done\" : false , \"status\" : \"pending\" }, { ID : 2 , \"title\" : \"doing more homework\" , \"done\" : false , \"status\" : \"new\" } ], \"count\" : 2 , \"nextId\" : 3 , \"nextUrl\" : \"http://localhost:5000/api/tasks/neptun/paged?from=3&count=2\" } GET /api/tasks/neptun/paged?from=3&count=2 This is to query the second page. Response: { \"items\" : [ { \"id\" : 3 , \"title\" : \"hosework\" , \"done\" : true , \"status\" : \"done\" } ], \"count\" : 1 , \"nextId\" : null , \"nextUrl\" : null } The response indicates no further pages as both nextId and nextUrl are null. GET /api/tasks/neptun/paged?from=999&count=999 Returns an empty page. Response: { \"items\" : [], \"count\" : 0 , \"nextId\" : null , \"nextUrl\" : null } SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows an arbitrary request and response of fetching a page. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Exercise 4: Optional exercise"},{"location":"Lab-EFREST/Exercise-4/#exercise-4-optional-exercise","text":"You can earn an additional +3 points with the completion of this exercise. (In the evaluation, you will see the text \"imsc\" in the exercise title; this is meant for the Hungarian students. Please ignore that.) If we have lots of tasks listing them should not return all of them at once. Implement a new endpoint to return a subset of the tasks (i.e., \"paging\"): It returns the tasks in a deterministic fashion sorted by ID. The query accepts a count parameter that specifies how many tasks to return. Specifying the next page is performed via a from parameter. This from is the ID of the first item to return on this page. Both the from and count are specified as query parameters. The new paging endpoint should be available on URL GET /api/tasks/neptun/paged (the /paged part is necessary so that the previous listing endpoint also remains functional). The response should return an instance of class Controllers.Dto.PagedTaskList . This includes: items : an array containing the tasks on the current page, count : specifying the number of items on the current page, nextId : id of the next task - to fetch the next page (to be used in from ), nextUrl : a helper URL that fetches the next page, or null if there are no further pages. Use the Url.Action helper method to assemble this URL. Do not hardcode \"localhost:5000\" or \"/api/tasks/paged\" in the source code! You will not need string operations to achieve this. Url.Action will give you an absolute URL when all parameters ( action , controller , values , protocol , and host ) are specified; for the latter ones this.HttpContext.Request can provide you the required values. The request always returns 200 OK; if there are no items, the result set shall be empty. The requests-responses shows you the expected behavior: GET /api/tasks/neptun/paged?count=2 This is the first request. There is no from value specified to start from the first item. Response: { \"items\" : [ { \"id\" : 1 , \"title\" : \"doing homework\" , \"done\" : false , \"status\" : \"pending\" }, { ID : 2 , \"title\" : \"doing more homework\" , \"done\" : false , \"status\" : \"new\" } ], \"count\" : 2 , \"nextId\" : 3 , \"nextUrl\" : \"http://localhost:5000/api/tasks/neptun/paged?from=3&count=2\" } GET /api/tasks/neptun/paged?from=3&count=2 This is to query the second page. Response: { \"items\" : [ { \"id\" : 3 , \"title\" : \"hosework\" , \"done\" : true , \"status\" : \"done\" } ], \"count\" : 1 , \"nextId\" : null , \"nextUrl\" : null } The response indicates no further pages as both nextId and nextUrl are null. GET /api/tasks/neptun/paged?from=999&count=999 Returns an empty page. Response: { \"items\" : [], \"count\" : 0 , \"nextId\" : null , \"nextUrl\" : null } SUBMISSION Create a screenshot in Postman (or an alternative tool you used) that shows an arbitrary request and response of fetching a page. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall include both the request and the response with all details (URL, body, response code, response body). Verify that your Neptun code is visible in the URL! The screenshot is required to earn the points.","title":"Exercise 4: Optional exercise"},{"location":"Lab-MSSQL/","text":"MSSQL \u00b6 In this lab, we will practice working with the server-side programming features of Microsoft SQL Server. Pre-requisites and preparation \u00b6 Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. Microsoft SQL Server The free Express version is sufficient, or you may also use localdb installed with Visual Studio A Linux version is also available. On macOS, you can use Docker. SQL Server Management Studio , or you may also use the platform-independent Azure Data Studio is Database initialization script: mssql.sql GitHub account and a git client Materials for preparing for this laboratory: Using Microsoft SQL Server: description and video The schema of the database Microsoft SQL Server server-side programming and the SQL language Check the materials of Data-driven systems including the seminars Initial steps \u00b6 Keep in mind that you are expected to follow the submission process . Create and check out your Git repository \u00b6 Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file. Create the database \u00b6 Connect to Microsoft SQL Server using SQL Server Management Studio. Start Management Studio and use the following connection details: Server name: (localdb)\\mssqllocaldb or .\\sqlexpress (which is short for: localhost\\sqlexpress ) Authentication: Windows authentication Create a new database (if it does not exist yet). The name should be your Neptun code : in Object Explorer right-click Databases and choose Create Database . IMPORTANT The name of the database must be your Neptun code . You will need to submit screenshots that display the database name this way! Create the sample database by executing the initializer script Open a new Query window, paste the script into the window, then execute it. Make sure to select the correct database in the toolbar dropdown. Verify that the tables are created. If the Tables folder was open before, you need to refresh it. .","title":"MSSQL"},{"location":"Lab-MSSQL/#mssql","text":"In this lab, we will practice working with the server-side programming features of Microsoft SQL Server.","title":"MSSQL"},{"location":"Lab-MSSQL/#pre-requisites-and-preparation","text":"Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. Microsoft SQL Server The free Express version is sufficient, or you may also use localdb installed with Visual Studio A Linux version is also available. On macOS, you can use Docker. SQL Server Management Studio , or you may also use the platform-independent Azure Data Studio is Database initialization script: mssql.sql GitHub account and a git client Materials for preparing for this laboratory: Using Microsoft SQL Server: description and video The schema of the database Microsoft SQL Server server-side programming and the SQL language Check the materials of Data-driven systems including the seminars","title":"Pre-requisites and preparation"},{"location":"Lab-MSSQL/#initial-steps","text":"Keep in mind that you are expected to follow the submission process .","title":"Initial steps"},{"location":"Lab-MSSQL/#create-and-check-out-your-git-repository","text":"Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file.","title":"Create and check out your Git repository"},{"location":"Lab-MSSQL/#create-the-database","text":"Connect to Microsoft SQL Server using SQL Server Management Studio. Start Management Studio and use the following connection details: Server name: (localdb)\\mssqllocaldb or .\\sqlexpress (which is short for: localhost\\sqlexpress ) Authentication: Windows authentication Create a new database (if it does not exist yet). The name should be your Neptun code : in Object Explorer right-click Databases and choose Create Database . IMPORTANT The name of the database must be your Neptun code . You will need to submit screenshots that display the database name this way! Create the sample database by executing the initializer script Open a new Query window, paste the script into the window, then execute it. Make sure to select the correct database in the toolbar dropdown. Verify that the tables are created. If the Tables folder was open before, you need to refresh it. .","title":"Create the database"},{"location":"Lab-MSSQL/Exercise-1/","text":"Exercise 1: Category view and data insertion \u00b6 You can earn 8 points with the completion of this exercise. Create a view \u00b6 Create a new CategoryWithParent view that lists the Category table's contents as follows. It should have two columns: the Name of the category and the name of the parent category (or null if it does not exist). Open a new Query window. Make sure to select the correct database. Create the view by executing the T-SQL command below. create view CategoryWithParent as select c . Name CategoryName , p . Name ParentCategoryName from Category c left outer join Category p on c . ParentCategoryId = p . ID Check the contents of the view! Insert via the view \u00b6 Create a trigger with the name InsertCategoryWithParent that allows inserting a new category through the view (that is, by specifying the category name and the parent category name). It is not necessary to set a parent category. Still, if it is specified and there is no category with the provided name, an error should be raised, and the operation aborted. You will need an instead of trigger that allows us to define how to insert the data. The skeleton of the trigger is provided below. create trigger InsertCategoryWithParent -- name of the trigger on CategoryWithParent -- name of the view instead of insert -- trigger code executed insted of insert as begin declare @ newname nvarchar ( 255 ) -- variables used below declare @ parentname nvarchar ( 255 ) -- using a cursor to navigate the inserted table declare ic cursor for select * from inserted open ic -- standard way of managing a cursor fetch next from ic into @ newname , @ parentname while @@ FETCH_STATUS = 0 begin -- check the received values available in the variables -- find the id of the parent, if specified -- throw error if anything is not right -- or insert the record into the Category table fetch next from ic into @ newname , @ parentname end close ic -- finish cursor usage deallocate ic end Finish this trigger by completing the code in the cycle. If a parent category name is provided, check whether any category with the same name as @parentname exists. If not, raise an error and abort the trigger. If everything is fine, insert the data into the Category table (and not the view... since the view does not store any data, hence this trigger). SUBMISSION Submit the code of the trigger in file f1-trigger.sql . The file should contain a single create trigger statement! Do not add [use] or go commands to the file! The correct behavior earns you 4 points. Verify the correct behavior of the trigger! Write an insert statement that successfully inserts a new category record through the view. Then write an insert statement that fails. Suppose that the database is in its initial state: the categories in the table are the ones included in the initializer script. The two tests should not depend on each other. Both shall produce the expected output regardless of whether the other was executed before! Use simple names It is recommended to use names (i.e., category names) that contain no special characters. Incorrect encoding of the SQL file might result in incorrect behavior otherwise. E.g., you may use the LEGO category as a known existing category. SUBMISSION Write the test insert statements into files f1-test-ok.sql and f1-test-error.sql . Each file shall contain a single insert statement! They should not include any use or go commands. Each file can earn you 2 points.","title":"Exercise 1: Category view and data insertion"},{"location":"Lab-MSSQL/Exercise-1/#exercise-1-category-view-and-data-insertion","text":"You can earn 8 points with the completion of this exercise.","title":"Exercise 1: Category view and data insertion"},{"location":"Lab-MSSQL/Exercise-1/#create-a-view","text":"Create a new CategoryWithParent view that lists the Category table's contents as follows. It should have two columns: the Name of the category and the name of the parent category (or null if it does not exist). Open a new Query window. Make sure to select the correct database. Create the view by executing the T-SQL command below. create view CategoryWithParent as select c . Name CategoryName , p . Name ParentCategoryName from Category c left outer join Category p on c . ParentCategoryId = p . ID Check the contents of the view!","title":"Create a view"},{"location":"Lab-MSSQL/Exercise-1/#insert-via-the-view","text":"Create a trigger with the name InsertCategoryWithParent that allows inserting a new category through the view (that is, by specifying the category name and the parent category name). It is not necessary to set a parent category. Still, if it is specified and there is no category with the provided name, an error should be raised, and the operation aborted. You will need an instead of trigger that allows us to define how to insert the data. The skeleton of the trigger is provided below. create trigger InsertCategoryWithParent -- name of the trigger on CategoryWithParent -- name of the view instead of insert -- trigger code executed insted of insert as begin declare @ newname nvarchar ( 255 ) -- variables used below declare @ parentname nvarchar ( 255 ) -- using a cursor to navigate the inserted table declare ic cursor for select * from inserted open ic -- standard way of managing a cursor fetch next from ic into @ newname , @ parentname while @@ FETCH_STATUS = 0 begin -- check the received values available in the variables -- find the id of the parent, if specified -- throw error if anything is not right -- or insert the record into the Category table fetch next from ic into @ newname , @ parentname end close ic -- finish cursor usage deallocate ic end Finish this trigger by completing the code in the cycle. If a parent category name is provided, check whether any category with the same name as @parentname exists. If not, raise an error and abort the trigger. If everything is fine, insert the data into the Category table (and not the view... since the view does not store any data, hence this trigger). SUBMISSION Submit the code of the trigger in file f1-trigger.sql . The file should contain a single create trigger statement! Do not add [use] or go commands to the file! The correct behavior earns you 4 points. Verify the correct behavior of the trigger! Write an insert statement that successfully inserts a new category record through the view. Then write an insert statement that fails. Suppose that the database is in its initial state: the categories in the table are the ones included in the initializer script. The two tests should not depend on each other. Both shall produce the expected output regardless of whether the other was executed before! Use simple names It is recommended to use names (i.e., category names) that contain no special characters. Incorrect encoding of the SQL file might result in incorrect behavior otherwise. E.g., you may use the LEGO category as a known existing category. SUBMISSION Write the test insert statements into files f1-test-ok.sql and f1-test-error.sql . Each file shall contain a single insert statement! They should not include any use or go commands. Each file can earn you 2 points.","title":"Insert via the view"},{"location":"Lab-MSSQL/Exercise-2/","text":"Exercise 2: Validating invoices \u00b6 You can earn 6 points with the completion of this exercise. Stored procedure \u00b6 Create a store procedure with the name CheckInvoice that expects an int input parameter with the name @invoiceid . The procedure shall check the invoice corresponding to the provided id: check each InvoiceItem whether the Amount equals the amount on the corresponding OrderItem . ( InvoiceItem directly references the corresponding OrderItem .) If there are any differences, print the amount values in both, and print the related product name as follows: Error: Ball (invoice 5 order 6) The procedure should print any message only if an error was found. Do not leave test output in the submitted code! The procedure return value shall be an int equal to 0 when no discrepancies were found and 1 in case one was identified. This value should be return -ed at the end of the procedure (do not use an output parameter). Use the print command for output as follows: PRINT 'Text' + @variable + 'Text' Any variable you print must be of character type. To convert a number to characters use: convert(varchar(5), @variable) , e.g. PRINT 'Text' + convert(varchar(5), @variable) SUBMISSION Write the stored procedure code in file f2-procedure.sql . The file should contain a single create proc statement! The correct behavior earns you 4 points. Partially incorrect behavior earns you partial points. Validate all invoices \u00b6 Write T-SQL code that calls the procedure on all invoices. You should use a cursor to iterate all invoices. The code shall print the ID of the invoice (e.g., InvoiceID: 12 ) before checking an invoice. If an invoice contains no discrepancies, print 'Invoice ok' before moving on to the next one. Check the Messages pane under the query window for the messages. Invoking a stored procedure Invoking a stored procedure is performed with the exec statement: declare @ checkresult int exec @ checkresult = CheckInvoice 123 Verify the correct behavior of this code. You might need to alter a few records in the database to have any discrepancies. (The testing code does not need to be submitted.) SUBMISSION Submit the code checking all invoices in file f2-check-all.sql . The file shall contain the T-SQL code. It should not include the stored procedure nor any use or go commands. You can earn 2 points with the completion of this task. SUBMISSION Create a screenshot of the output when a discrepancy was found . Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall display the database name (which should be your Neptun code ) in the Object Explorer window and the output messages too.","title":"Exercise 2: Validating invoices"},{"location":"Lab-MSSQL/Exercise-2/#exercise-2-validating-invoices","text":"You can earn 6 points with the completion of this exercise.","title":"Exercise 2: Validating invoices"},{"location":"Lab-MSSQL/Exercise-2/#stored-procedure","text":"Create a store procedure with the name CheckInvoice that expects an int input parameter with the name @invoiceid . The procedure shall check the invoice corresponding to the provided id: check each InvoiceItem whether the Amount equals the amount on the corresponding OrderItem . ( InvoiceItem directly references the corresponding OrderItem .) If there are any differences, print the amount values in both, and print the related product name as follows: Error: Ball (invoice 5 order 6) The procedure should print any message only if an error was found. Do not leave test output in the submitted code! The procedure return value shall be an int equal to 0 when no discrepancies were found and 1 in case one was identified. This value should be return -ed at the end of the procedure (do not use an output parameter). Use the print command for output as follows: PRINT 'Text' + @variable + 'Text' Any variable you print must be of character type. To convert a number to characters use: convert(varchar(5), @variable) , e.g. PRINT 'Text' + convert(varchar(5), @variable) SUBMISSION Write the stored procedure code in file f2-procedure.sql . The file should contain a single create proc statement! The correct behavior earns you 4 points. Partially incorrect behavior earns you partial points.","title":"Stored procedure"},{"location":"Lab-MSSQL/Exercise-2/#validate-all-invoices","text":"Write T-SQL code that calls the procedure on all invoices. You should use a cursor to iterate all invoices. The code shall print the ID of the invoice (e.g., InvoiceID: 12 ) before checking an invoice. If an invoice contains no discrepancies, print 'Invoice ok' before moving on to the next one. Check the Messages pane under the query window for the messages. Invoking a stored procedure Invoking a stored procedure is performed with the exec statement: declare @ checkresult int exec @ checkresult = CheckInvoice 123 Verify the correct behavior of this code. You might need to alter a few records in the database to have any discrepancies. (The testing code does not need to be submitted.) SUBMISSION Submit the code checking all invoices in file f2-check-all.sql . The file shall contain the T-SQL code. It should not include the stored procedure nor any use or go commands. You can earn 2 points with the completion of this task. SUBMISSION Create a screenshot of the output when a discrepancy was found . Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall display the database name (which should be your Neptun code ) in the Object Explorer window and the output messages too.","title":"Validate all invoices"},{"location":"Lab-MSSQL/Exercise-3/","text":"Exercise 3: Denormalize invoices \u00b6 You can earn 6 points with the completion of this exercise. New column \u00b6 Update the Invoice table by adding a new ItemCount integer column that contains the number of items on the invoice (regarding the InvoiceItems records associated with each invoice). SUBMISSION The code for adding the column shall be submitted in file f3-column.sql . The file shall contain a single alter table statement and should not include any use or go commands. You can earn 1 point with the completion of this task. This task is a prerequisite for the next ones. Write T-SQL code block to fill this new column with the correct values. If an Invoice has an associated item with 2 red beach balls and another item with 1 tennis racket, then there are 3 items on this invoice. Note that it is invoices (and not orders) you have to consider here! SUBMISSION Submit the code in file f3-fill.sql . The file shall contain a single T-SQL code block. Do not use stored procedures or triggers here, and the code should not have any [use] or go statements either. You can earn 1 point with the completion of this task. Maintaining the correct value \u00b6 Create a trigger with the name InvoiceItemCountMaintenance that ensures the value in this new column is updated when an invoice or related items are updated. The trigger must be efficient! Re-calculating the number of items is not an acceptable solution. The trigger must also work correctly when multiple items are updated at the same time. Tip The trigger shall be on the InvoiceItem table despite the new column being in the Invoice table. Important Do not forget that triggers are executed per statement and not for each row; that is, your trigger will need to handle multiple changes in the implicit tables! The inserted and deleted implicit variables are tables must be treated as such. SUBMISSION Submit the code of the trigger in file f3-trigger.sql . The file shall contain a single create trigger statement and should not contain any use or go commands. The correct behavior earns you 4 points. Partially incorrect behavior earns you partial points. Verify the correct behavior of the trigger! The test code need not be submitted, but make sure to verify the behavior. Make sure to check the case when multiple records are modified with a single statement, e.g., execute an update without a where condition). SUBMISSION Create a screenshot displaying the contents of the table Invoice with the ItemCount column and its correctly filled values. Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall display the database name (which should be your Neptun code ) in the Object Explorer window and the contents of the Invoice table . The screenshot is required to earn the points of this part of the exercise.","title":"Exercise 3: Denormalize invoices"},{"location":"Lab-MSSQL/Exercise-3/#exercise-3-denormalize-invoices","text":"You can earn 6 points with the completion of this exercise.","title":"Exercise 3: Denormalize invoices"},{"location":"Lab-MSSQL/Exercise-3/#new-column","text":"Update the Invoice table by adding a new ItemCount integer column that contains the number of items on the invoice (regarding the InvoiceItems records associated with each invoice). SUBMISSION The code for adding the column shall be submitted in file f3-column.sql . The file shall contain a single alter table statement and should not include any use or go commands. You can earn 1 point with the completion of this task. This task is a prerequisite for the next ones. Write T-SQL code block to fill this new column with the correct values. If an Invoice has an associated item with 2 red beach balls and another item with 1 tennis racket, then there are 3 items on this invoice. Note that it is invoices (and not orders) you have to consider here! SUBMISSION Submit the code in file f3-fill.sql . The file shall contain a single T-SQL code block. Do not use stored procedures or triggers here, and the code should not have any [use] or go statements either. You can earn 1 point with the completion of this task.","title":"New column"},{"location":"Lab-MSSQL/Exercise-3/#maintaining-the-correct-value","text":"Create a trigger with the name InvoiceItemCountMaintenance that ensures the value in this new column is updated when an invoice or related items are updated. The trigger must be efficient! Re-calculating the number of items is not an acceptable solution. The trigger must also work correctly when multiple items are updated at the same time. Tip The trigger shall be on the InvoiceItem table despite the new column being in the Invoice table. Important Do not forget that triggers are executed per statement and not for each row; that is, your trigger will need to handle multiple changes in the implicit tables! The inserted and deleted implicit variables are tables must be treated as such. SUBMISSION Submit the code of the trigger in file f3-trigger.sql . The file shall contain a single create trigger statement and should not contain any use or go commands. The correct behavior earns you 4 points. Partially incorrect behavior earns you partial points. Verify the correct behavior of the trigger! The test code need not be submitted, but make sure to verify the behavior. Make sure to check the case when multiple records are modified with a single statement, e.g., execute an update without a where condition). SUBMISSION Create a screenshot displaying the contents of the table Invoice with the ItemCount column and its correctly filled values. Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall display the database name (which should be your Neptun code ) in the Object Explorer window and the contents of the Invoice table . The screenshot is required to earn the points of this part of the exercise.","title":"Maintaining the correct value"},{"location":"Lab-MSSQL/Exercise-4/","text":"Exercise 4: Optional exercise \u00b6 You can earn an additional +3 points with the completion of this exercise. (In the evaluation, you will see the text \"imsc\" in the exercise title; this is meant for the Hungarian students. Please ignore that.) Query the Categories so that you get the following outcome: Name Count Rank Building items 3 1 Months 0-6 2 2 DUPLO 1 3 LEGO 1 4 Months 18-24 1 5 Months 6-18 1 6 Play house 1 7 The first column is the name of the category. The second column contains the number of products in this category. And finally, the third is the rank of the results based on the number of products in the category, descending; if the counts are equal, then the order is based on the name of the category ascending. The ranking should be continuous without gaps, and the final results should be ordered by this rank. The query should be a single statement. The name of the columns in the result set should be the ones you see above. Tip The fact that the third column is called \"rank\" should give you an idea. SUBMISSION Submit the query in file f4.sql . The file shall contain a single select query without any use or go commands. SUBMISSION Create a screenshot that shows the outcome of the query. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall display the database name (which should be your Neptun code ) in the Object Explorer window and the query results . The screenshot is required to earn the points.","title":"Exercise 4: Optional exercise"},{"location":"Lab-MSSQL/Exercise-4/#exercise-4-optional-exercise","text":"You can earn an additional +3 points with the completion of this exercise. (In the evaluation, you will see the text \"imsc\" in the exercise title; this is meant for the Hungarian students. Please ignore that.) Query the Categories so that you get the following outcome: Name Count Rank Building items 3 1 Months 0-6 2 2 DUPLO 1 3 LEGO 1 4 Months 18-24 1 5 Months 6-18 1 6 Play house 1 7 The first column is the name of the category. The second column contains the number of products in this category. And finally, the third is the rank of the results based on the number of products in the category, descending; if the counts are equal, then the order is based on the name of the category ascending. The ranking should be continuous without gaps, and the final results should be ordered by this rank. The query should be a single statement. The name of the columns in the result set should be the ones you see above. Tip The fact that the third column is called \"rank\" should give you an idea. SUBMISSION Submit the query in file f4.sql . The file shall contain a single select query without any use or go commands. SUBMISSION Create a screenshot that shows the outcome of the query. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall display the database name (which should be your Neptun code ) in the Object Explorer window and the query results . The screenshot is required to earn the points.","title":"Exercise 4: Optional exercise"},{"location":"Lab-MongoDB/","text":"MongoDB \u00b6 In this lab, we will work with the MongoDB NoSQL database and the Mongo C# driver. Pre-requisites and preparation \u00b6 Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. MongoDB Community Server ( download ) Robo 3T ( download ) Without installing you can run the server with the following command using Docker: cmd docker run --name swlab1-mongo -p 27017:27017 -d mongo Sample database initialization script: ( mongo.js ) GitHub account and a git client Microsoft Visual Studio 2022 with the settings here When using Linux or macOS, you can use Visual Studio Code, the .NET SDK, and dotnet CLI . .NET Core 6.0 SDK .NET 6.0 Mind the version! You need .NET SDK version 6.0 to solve these exercises. On Windows it might already be installed along with Visual Studio (see here how to check it); if not, use the link above to install (the SDK and not the runtime). You need to install it manually when using Linux or macOS. Materials for preparing for this laboratory: MongoDB database system and the C# driver Check the materials of Data-driven systems including the seminars Official Microsoft tutorial for WebApi using MongoDB We will not be creating a WebApi in this lab, but the Mongo part is the same. Initial steps \u00b6 Keep in mind that you are expected to follow the submission process . Create and check out your Git repository \u00b6 Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. Password in the labs If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file. Create the database \u00b6 Follow the steps in the seminar material to start the database server and initialize the database.","title":"MongoDB"},{"location":"Lab-MongoDB/#mongodb","text":"In this lab, we will work with the MongoDB NoSQL database and the Mongo C# driver.","title":"MongoDB"},{"location":"Lab-MongoDB/#pre-requisites-and-preparation","text":"Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. MongoDB Community Server ( download ) Robo 3T ( download ) Without installing you can run the server with the following command using Docker: cmd docker run --name swlab1-mongo -p 27017:27017 -d mongo Sample database initialization script: ( mongo.js ) GitHub account and a git client Microsoft Visual Studio 2022 with the settings here When using Linux or macOS, you can use Visual Studio Code, the .NET SDK, and dotnet CLI . .NET Core 6.0 SDK .NET 6.0 Mind the version! You need .NET SDK version 6.0 to solve these exercises. On Windows it might already be installed along with Visual Studio (see here how to check it); if not, use the link above to install (the SDK and not the runtime). You need to install it manually when using Linux or macOS. Materials for preparing for this laboratory: MongoDB database system and the C# driver Check the materials of Data-driven systems including the seminars Official Microsoft tutorial for WebApi using MongoDB We will not be creating a WebApi in this lab, but the Mongo part is the same.","title":"Pre-requisites and preparation"},{"location":"Lab-MongoDB/#initial-steps","text":"Keep in mind that you are expected to follow the submission process .","title":"Initial steps"},{"location":"Lab-MongoDB/#create-and-check-out-your-git-repository","text":"Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. Password in the labs If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file.","title":"Create and check out your Git repository"},{"location":"Lab-MongoDB/#create-the-database","text":"Follow the steps in the seminar material to start the database server and initialize the database.","title":"Create the database"},{"location":"Lab-MongoDB/Exercise-1/","text":"Exercise 1: Listing and modifying products \u00b6 You can earn 7 points with the completion of this exercise. This exercise will implement CRUD (create, retrieve, update, delete) operations for Product entities. Open the Visual Studio solution \u00b6 Open the Visual Studio solution (the .sln ) file in the checked-out repository. If Visual Studio tells you that the project is not supported, you need to install a missing component (see here ). Do NOT upgrade any version Do not upgrade the project, the .NET Core version, or any Nuget package! If you see such a question, always choose no! You will need to work in class mongolab.DAL.Repository ! You can make changes to this class as long as the source code complies, the repository implements interface mongolab.DAL.IRepository , and the constructor accepts a single IMongoDatabase parameter. The database access is configured in class mongolab.DAL.MongoConnectionConfig . If needed, you can change the database name in this file. Other parts of the application should NOT be modified! The web application is a so-called Razor Pages ASP.NET Core project. It includes a presentation layer rendered on the server using C# code and the Razor engine. (You do not need to concern yourself with the UI.) Start the web app \u00b6 Check if the web application starts. Compile the code and start in Visual Studio. Open URL http://localhost:5000/ in a browser. If everything was successful, you should see a page with links where you will be able to test your code. (The links will not work as the data access layer is not implemented yet.) Display the Neptun code on the web page \u00b6 You will need to create screenshots that display your Neptun code. Open file Pages\\Shared\\_Layout.cshtml . In the middle of the file, find the following section, and edit your Neptun code. < div class = \"container body-content\" > @RenderBody () < hr /> < footer > < p > @ViewData [ \"Title\" ] - NEPTUN </ p > </ footer > </ div > Compile the code and start the app again, then check the starting page. You should see the Neptune code at the bottom of the page. IMPORTANT The Neptun code is a mandatory requirement in the footer! Listing \u00b6 First, you will need a way to access the products collection from C#. Create and initialize a new variable that represents the collection in class Repository . Use the injected IMongoDatabase variable to get the collection: private readonly IMongoCollection < Entities . Product > productCollection ; public Repository ( IMongoDatabase database ) { this . productCollection = database . GetCollection < Entities . Product >( \"products\" ); } You can use productCollection to access the database's product records from now on. Let us start by implementing ListProducts . This will require two steps: first, to query the data from the database, then transform each record to an instance of Models.Product . The query is as follows: var dbProducts = productCollection . Find ( _ => true ) // listing all products hence an empty filter . ToList (); All items are then transformed. return dbProducts . Select ( t => new Product { ID = t . ID . ToString (), Name = t . Name , Price = t . Price , Stock = t . Stock }) . ToList (); The implementation of FindProduct(string id) is similar, except for querying a single record by matching the ID . Pay attention to the fact that the ID is received as a string, but it needs converting to ObjectId . The transformation to the model remains identical. However, we should also handle when there is no matching record found and return a null value in this case (without converting anything to a model). The query is as follows: var dbProduct = productCollection . Find ( t => t . ID == ObjectId . Parse ( id )) . SingleOrDefault (); // ... model conversion Note how the filter expression looks like! Also, note how the ToList is replaced with a SingleOrDefault call. This returns either the first (and single) element in the result set or null when there is none. This is a generic way of querying a single record from the database. You will need to write a similar code in further exercises. The conversion/transformation code is already given; however, we should prepare to handle when dbProduct is null . Instead of conversion, we should return null then. Test the behavior of these queries! Start the web application and go to http://localhost:5000 in a browser. Click Products to list the data from the database. If you click on Details it will show the details of the selected product. If you do not see any product If you see no items on this page, but there is no error, it is most likely due to a misconfigured database access. MongoDB will not return an error if the specified database does not exist. See the instructions for changing the connection details above. Creation \u00b6 Implement the method InsertProduct(Product product) . The input is an instance of Models.Product that collects the information specified on the UI. To create a new product, we will first create a new database entity (in memory first). This is an instance of class Entities.Product . There is no need to set the ID - the database will generate it. Name , Price and Stock are provided by the user. What is left is VAT and CategoryID . We should hard-code values here: create a new VAT entity and find a random category using Robo3T and copy the _id value. var dbProduct = new Entities . Product { Name = product . Name , Price = product . Price , Stock = product . Stock , VAT = new Entities . VAT { Name = \"General\" , Percentage = 20 }, CategoryID = ObjectId . Parse ( \"5d7e4370cffa8e1030fd2d99\" ), }; // ... insertion Once the database entity is ready, use InsertOne to add it to the database. To test your code, start the application and click the Add new product link on the products page. You will need to fill in the necessary data, and then the presentation layer will call your code. Delete \u00b6 Implement method DeleteProduct(string id) . Use DeleteOne on the collection to delete the record. You will need a filter expression here to find the matching record similarly to how it was done in FindProduct(string id) . Test the functionality using the web application by clicking the Delete link next to a product. Modification \u00b6 We will implement the method bool SellProduct(string id, int amount) as a modification operation. The method shall return true if a record with a matching id is found, and there are at least amount pieces in stock. If the product is not found or there is not enough in stock return false . Using the atomicity guarantees of MongoDB, we will perform the changes in a single step. A filter will be used to find both the id and check if there are enough items in stock. A modification will decrease the stock only if the filter is matched. var result = productCollection . UpdateOne ( filter : t => t . ID == ObjectId . Parse ( id ) && t . Stock >= amount , update : Builders < Entities . Product >. Update . Inc ( t => t . Stock , - amount ), options : new UpdateOptions { IsUpsert = false }); Note that the UpdateOptions is used to signal that we do NOT want as upsert operation; instead, we want the operation to do nothing when the filter is not matched. The modification is assembled using Update in Builders . Here we want to decrease the stock value with amount (which is, effectively, an increase with -amount ). We can determine what happened based on the result returned by the update operation. If the result indicates that the filter matched a record and the modification was performed, return true . Otherwise, return false . return result . MatchedCount > 0 ; Test the functionality using the web application by clicking the Buy link next to a product. Verify the behavior when you enter a too large amount! SUBMISSION Create a screenshot of the web page listing the products after successfully adding at least one new product . Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall display the list of products . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 1: Listing and modifying products"},{"location":"Lab-MongoDB/Exercise-1/#exercise-1-listing-and-modifying-products","text":"You can earn 7 points with the completion of this exercise. This exercise will implement CRUD (create, retrieve, update, delete) operations for Product entities.","title":"Exercise 1: Listing and modifying products"},{"location":"Lab-MongoDB/Exercise-1/#open-the-visual-studio-solution","text":"Open the Visual Studio solution (the .sln ) file in the checked-out repository. If Visual Studio tells you that the project is not supported, you need to install a missing component (see here ). Do NOT upgrade any version Do not upgrade the project, the .NET Core version, or any Nuget package! If you see such a question, always choose no! You will need to work in class mongolab.DAL.Repository ! You can make changes to this class as long as the source code complies, the repository implements interface mongolab.DAL.IRepository , and the constructor accepts a single IMongoDatabase parameter. The database access is configured in class mongolab.DAL.MongoConnectionConfig . If needed, you can change the database name in this file. Other parts of the application should NOT be modified! The web application is a so-called Razor Pages ASP.NET Core project. It includes a presentation layer rendered on the server using C# code and the Razor engine. (You do not need to concern yourself with the UI.)","title":"Open the Visual Studio solution"},{"location":"Lab-MongoDB/Exercise-1/#start-the-web-app","text":"Check if the web application starts. Compile the code and start in Visual Studio. Open URL http://localhost:5000/ in a browser. If everything was successful, you should see a page with links where you will be able to test your code. (The links will not work as the data access layer is not implemented yet.)","title":"Start the web app"},{"location":"Lab-MongoDB/Exercise-1/#display-the-neptun-code-on-the-web-page","text":"You will need to create screenshots that display your Neptun code. Open file Pages\\Shared\\_Layout.cshtml . In the middle of the file, find the following section, and edit your Neptun code. < div class = \"container body-content\" > @RenderBody () < hr /> < footer > < p > @ViewData [ \"Title\" ] - NEPTUN </ p > </ footer > </ div > Compile the code and start the app again, then check the starting page. You should see the Neptune code at the bottom of the page. IMPORTANT The Neptun code is a mandatory requirement in the footer!","title":"Display the Neptun code on the web page"},{"location":"Lab-MongoDB/Exercise-1/#listing","text":"First, you will need a way to access the products collection from C#. Create and initialize a new variable that represents the collection in class Repository . Use the injected IMongoDatabase variable to get the collection: private readonly IMongoCollection < Entities . Product > productCollection ; public Repository ( IMongoDatabase database ) { this . productCollection = database . GetCollection < Entities . Product >( \"products\" ); } You can use productCollection to access the database's product records from now on. Let us start by implementing ListProducts . This will require two steps: first, to query the data from the database, then transform each record to an instance of Models.Product . The query is as follows: var dbProducts = productCollection . Find ( _ => true ) // listing all products hence an empty filter . ToList (); All items are then transformed. return dbProducts . Select ( t => new Product { ID = t . ID . ToString (), Name = t . Name , Price = t . Price , Stock = t . Stock }) . ToList (); The implementation of FindProduct(string id) is similar, except for querying a single record by matching the ID . Pay attention to the fact that the ID is received as a string, but it needs converting to ObjectId . The transformation to the model remains identical. However, we should also handle when there is no matching record found and return a null value in this case (without converting anything to a model). The query is as follows: var dbProduct = productCollection . Find ( t => t . ID == ObjectId . Parse ( id )) . SingleOrDefault (); // ... model conversion Note how the filter expression looks like! Also, note how the ToList is replaced with a SingleOrDefault call. This returns either the first (and single) element in the result set or null when there is none. This is a generic way of querying a single record from the database. You will need to write a similar code in further exercises. The conversion/transformation code is already given; however, we should prepare to handle when dbProduct is null . Instead of conversion, we should return null then. Test the behavior of these queries! Start the web application and go to http://localhost:5000 in a browser. Click Products to list the data from the database. If you click on Details it will show the details of the selected product. If you do not see any product If you see no items on this page, but there is no error, it is most likely due to a misconfigured database access. MongoDB will not return an error if the specified database does not exist. See the instructions for changing the connection details above.","title":"Listing"},{"location":"Lab-MongoDB/Exercise-1/#creation","text":"Implement the method InsertProduct(Product product) . The input is an instance of Models.Product that collects the information specified on the UI. To create a new product, we will first create a new database entity (in memory first). This is an instance of class Entities.Product . There is no need to set the ID - the database will generate it. Name , Price and Stock are provided by the user. What is left is VAT and CategoryID . We should hard-code values here: create a new VAT entity and find a random category using Robo3T and copy the _id value. var dbProduct = new Entities . Product { Name = product . Name , Price = product . Price , Stock = product . Stock , VAT = new Entities . VAT { Name = \"General\" , Percentage = 20 }, CategoryID = ObjectId . Parse ( \"5d7e4370cffa8e1030fd2d99\" ), }; // ... insertion Once the database entity is ready, use InsertOne to add it to the database. To test your code, start the application and click the Add new product link on the products page. You will need to fill in the necessary data, and then the presentation layer will call your code.","title":"Creation"},{"location":"Lab-MongoDB/Exercise-1/#delete","text":"Implement method DeleteProduct(string id) . Use DeleteOne on the collection to delete the record. You will need a filter expression here to find the matching record similarly to how it was done in FindProduct(string id) . Test the functionality using the web application by clicking the Delete link next to a product.","title":"Delete"},{"location":"Lab-MongoDB/Exercise-1/#modification","text":"We will implement the method bool SellProduct(string id, int amount) as a modification operation. The method shall return true if a record with a matching id is found, and there are at least amount pieces in stock. If the product is not found or there is not enough in stock return false . Using the atomicity guarantees of MongoDB, we will perform the changes in a single step. A filter will be used to find both the id and check if there are enough items in stock. A modification will decrease the stock only if the filter is matched. var result = productCollection . UpdateOne ( filter : t => t . ID == ObjectId . Parse ( id ) && t . Stock >= amount , update : Builders < Entities . Product >. Update . Inc ( t => t . Stock , - amount ), options : new UpdateOptions { IsUpsert = false }); Note that the UpdateOptions is used to signal that we do NOT want as upsert operation; instead, we want the operation to do nothing when the filter is not matched. The modification is assembled using Update in Builders . Here we want to decrease the stock value with amount (which is, effectively, an increase with -amount ). We can determine what happened based on the result returned by the update operation. If the result indicates that the filter matched a record and the modification was performed, return true . Otherwise, return false . return result . MatchedCount > 0 ; Test the functionality using the web application by clicking the Buy link next to a product. Verify the behavior when you enter a too large amount! SUBMISSION Create a screenshot of the web page listing the products after successfully adding at least one new product . Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall display the list of products . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Modification"},{"location":"Lab-MongoDB/Exercise-2/","text":"Exercise 2: Listing categories \u00b6 You can earn 4 points with the completion of this exercise. We will be listing available categories here with the number of products in each category. We will need an aggregation pipeline here. Continue working in class MongoLabor.DAL.Repository . The method you should implement is IList<Category> ListCategories() . The method shall return all categories. Class Models.Category has 3 members. Name : the name of the category ParentCategoryName : the name of the parent category. If there is no parent, the value should be null . NumberOfProducts : number of products in this category. If there are no products, the value should be 0 . The outline of the solution is as follows. Create and initialize a new productCollection similar to how categoryCollection is initialized. The name of the collection is categories - you can verify this using Robo3T . ListCategories() should first query all categories. Perform this similarly to how it was done in the previous exercise. Store the result set in variable dbCategories . Query the number of products associated with each category ( Product.CategoryID ). Use an aggregation pipeline and a $group step as follows. var productCounts = productCollection . Aggregate () . Group ( t => t . CategoryID , g => new { CategoryID = g . Key , NumberOfProducts = g . Count () }) . ToList (); This query yields a list where each item has a CategoryID and the number of associated products. We have all information we need: all categories (including the parents) and the number of products for each. The final step is to \"merge\" the results in C# code. return dbCategories . Select ( c => { string parentCategoryName = null ; if ( c . ParentCategoryID . HasValue ) parentCategoryName = dbCategories . Single ( p => p . ID == c . ParentCategoryID . Value ). Name ; var numProd = productCounts . SingleOrDefault ( pc => pc . CategoryID == c . ID )?. NumberOfProducts ?? 0 ; return new Category { Name = c . Name , ParentCategoryName = parentCategoryName , NumberOfProducts = numProd }; }) . ToList (); As seen above, this is performed using LINQ. This is not the only solution to \"join\" collections in MongoDB. Although there is no join operation, there are ways to query data across collections. Instead of doing this in MongoDB, we do the merging in C# as above. This would not be good if the data set were large. Also, if there were filtering involved, the code above would be much more complicated. Use the Categories link of the website to test your solution. This will list the data provided by your code in a tabular format. You can use the Add new product functionality from before to create new products. This must result in an increase in the number of products in one of the categories. (Remember that inserting the product hard-coded a category ID.) SUBMISSION Create a screenshot of the web page listing the categories. Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall display the list of categories . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 2: Listing categories"},{"location":"Lab-MongoDB/Exercise-2/#exercise-2-listing-categories","text":"You can earn 4 points with the completion of this exercise. We will be listing available categories here with the number of products in each category. We will need an aggregation pipeline here. Continue working in class MongoLabor.DAL.Repository . The method you should implement is IList<Category> ListCategories() . The method shall return all categories. Class Models.Category has 3 members. Name : the name of the category ParentCategoryName : the name of the parent category. If there is no parent, the value should be null . NumberOfProducts : number of products in this category. If there are no products, the value should be 0 . The outline of the solution is as follows. Create and initialize a new productCollection similar to how categoryCollection is initialized. The name of the collection is categories - you can verify this using Robo3T . ListCategories() should first query all categories. Perform this similarly to how it was done in the previous exercise. Store the result set in variable dbCategories . Query the number of products associated with each category ( Product.CategoryID ). Use an aggregation pipeline and a $group step as follows. var productCounts = productCollection . Aggregate () . Group ( t => t . CategoryID , g => new { CategoryID = g . Key , NumberOfProducts = g . Count () }) . ToList (); This query yields a list where each item has a CategoryID and the number of associated products. We have all information we need: all categories (including the parents) and the number of products for each. The final step is to \"merge\" the results in C# code. return dbCategories . Select ( c => { string parentCategoryName = null ; if ( c . ParentCategoryID . HasValue ) parentCategoryName = dbCategories . Single ( p => p . ID == c . ParentCategoryID . Value ). Name ; var numProd = productCounts . SingleOrDefault ( pc => pc . CategoryID == c . ID )?. NumberOfProducts ?? 0 ; return new Category { Name = c . Name , ParentCategoryName = parentCategoryName , NumberOfProducts = numProd }; }) . ToList (); As seen above, this is performed using LINQ. This is not the only solution to \"join\" collections in MongoDB. Although there is no join operation, there are ways to query data across collections. Instead of doing this in MongoDB, we do the merging in C# as above. This would not be good if the data set were large. Also, if there were filtering involved, the code above would be much more complicated. Use the Categories link of the website to test your solution. This will list the data provided by your code in a tabular format. You can use the Add new product functionality from before to create new products. This must result in an increase in the number of products in one of the categories. (Remember that inserting the product hard-coded a category ID.) SUBMISSION Create a screenshot of the web page listing the categories. Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall display the list of categories . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 2: Listing categories"},{"location":"Lab-MongoDB/Exercise-3/","text":"Exercise 3: Querying and modifying orders \u00b6 You can earn 5 points with the completion of this exercise. In this exercise, we will implement CRUD (create, retrieve, update, delete) operations for Order entities. This exercise is similar to the previous one; feel free to look back to the solutions of that exercise. The properties of Model.Order are: ID : the ID of the database serialized using ToString Date , Deadline , Status : taken from the database directly PaymentMethod : taken from the Method field of the PaymentMethod complex entity Total : the cumulative sum of the product of Amount and Price for all items associated with this order ( OrderItems ) You will need to implement the management methods related to orders: ListOrders , FindOrder , InsertOrder , DeleteOrder , and UpdateOrder . Before starting the tasks below, do not forget to add and initialize an orderCollection in the repository class similar to the other one. Listing \u00b6 Method ListOrders receives a string status parameter. If this value is empty or null (see: string.IsNullOrEmpty ) list all orders. Otherwise, list orders where the Status field is identical to the status received as a parameter. Method FindOrder returns the data of a single order identified by string id . If no record with the same ID exists, this method shall return null . Creation \u00b6 Implement the method InsertOrder . The following information is provided to create the new order: Order order , Product product , and int amount . You need the set the following information in the database entity: CustomerID , SiteID : find a chosen Customer in the database and copy the values from this record from fields _id and mainSiteId . Hard-wire these values in code. Date , Deadline , Status : take these values from the value received as order parameter PaymentMethod : create a new instance of PaymentMethod . The Method should be PaymentMethod from the object received through the order parameter. Leave Deadline as null . OrderItems : create a single item here with the following data: ProductID and Price : take the values from the parameter product Amount : copy value from the method parameter amount Status : equals to the Status field of parameter order other fields (related to invoicing) should be left as null ! Delete \u00b6 DeleteOrder should delete the record specified by the ID . Modification \u00b6 When updating the record in UpdateOrder , only update the information present in Models.Order : Date , Deadline , Status , and PaymentMethod . Ignore the value Total ; it does not need to be considered in this context. You can combine multiple updates using Builders<Entities.Order>.Update.Combine . Keep in mind that the IsUpsert property should be set to false in the update! The method should return true if there were a record with a matching ID . Testing \u00b6 You can test the functionalities using the Orders link in the test web app. Verify the behavior of Filter , Add new order , Edit , Details , and Delete too! SUBMISSION Create a screenshot of the web page listing the orders after successfully adding at least one new order . Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall display the list of orders . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 3: Querying and modifying orders"},{"location":"Lab-MongoDB/Exercise-3/#exercise-3-querying-and-modifying-orders","text":"You can earn 5 points with the completion of this exercise. In this exercise, we will implement CRUD (create, retrieve, update, delete) operations for Order entities. This exercise is similar to the previous one; feel free to look back to the solutions of that exercise. The properties of Model.Order are: ID : the ID of the database serialized using ToString Date , Deadline , Status : taken from the database directly PaymentMethod : taken from the Method field of the PaymentMethod complex entity Total : the cumulative sum of the product of Amount and Price for all items associated with this order ( OrderItems ) You will need to implement the management methods related to orders: ListOrders , FindOrder , InsertOrder , DeleteOrder , and UpdateOrder . Before starting the tasks below, do not forget to add and initialize an orderCollection in the repository class similar to the other one.","title":"Exercise 3: Querying and modifying orders"},{"location":"Lab-MongoDB/Exercise-3/#listing","text":"Method ListOrders receives a string status parameter. If this value is empty or null (see: string.IsNullOrEmpty ) list all orders. Otherwise, list orders where the Status field is identical to the status received as a parameter. Method FindOrder returns the data of a single order identified by string id . If no record with the same ID exists, this method shall return null .","title":"Listing"},{"location":"Lab-MongoDB/Exercise-3/#creation","text":"Implement the method InsertOrder . The following information is provided to create the new order: Order order , Product product , and int amount . You need the set the following information in the database entity: CustomerID , SiteID : find a chosen Customer in the database and copy the values from this record from fields _id and mainSiteId . Hard-wire these values in code. Date , Deadline , Status : take these values from the value received as order parameter PaymentMethod : create a new instance of PaymentMethod . The Method should be PaymentMethod from the object received through the order parameter. Leave Deadline as null . OrderItems : create a single item here with the following data: ProductID and Price : take the values from the parameter product Amount : copy value from the method parameter amount Status : equals to the Status field of parameter order other fields (related to invoicing) should be left as null !","title":"Creation"},{"location":"Lab-MongoDB/Exercise-3/#delete","text":"DeleteOrder should delete the record specified by the ID .","title":"Delete"},{"location":"Lab-MongoDB/Exercise-3/#modification","text":"When updating the record in UpdateOrder , only update the information present in Models.Order : Date , Deadline , Status , and PaymentMethod . Ignore the value Total ; it does not need to be considered in this context. You can combine multiple updates using Builders<Entities.Order>.Update.Combine . Keep in mind that the IsUpsert property should be set to false in the update! The method should return true if there were a record with a matching ID .","title":"Modification"},{"location":"Lab-MongoDB/Exercise-3/#testing","text":"You can test the functionalities using the Orders link in the test web app. Verify the behavior of Filter , Add new order , Edit , Details , and Delete too! SUBMISSION Create a screenshot of the web page listing the orders after successfully adding at least one new order . Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall display the list of orders . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Testing"},{"location":"Lab-MongoDB/Exercise-4/","text":"Exercise 4: Listing customers \u00b6 You can earn 4 points with the completion of this exercise. We will list the customers in this exercise, along with the cumulative value of their orders. This will be similar to exercise 2: we will use aggregation and merging in C# code. The method to implement is IList<Customer> ListCustomers() . The method shall return every customer. The properties of Model.Customer are: Name : the name of the customer ZipCode , City , Street : the address fields of the main site of the customer TotalOrders : the cumulative total of all orders of the customer. You have to aggregate the price*amount for each order of a customer to get this total. If a particular customer has no orders, this value shall be null . Follow these steps to solve this exercise: Create and initialize the customerCollection . List all customers. The customer entity has the list of Sites ; the main site is the item MainSiteID points to. Use this value to find the main in among the list. In the collection of the orders, use an aggregation pipeline to calculate the total of all orders for each CustomerID . Finally, you need the \"merge\" the two result sets. Every customer has a main site; however, not all of them have orders (in which case TotalOrders shall be null ). Use the Customers link of the website to test your solution. This will list the data provided by your code in a tabular format. You can use the Add new order functionality from before to create new orders. This must result in an increase in the total for one of the customers. SUBMISSION Create a screenshot of the web page listing the customers. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall display the list of customers . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 4: Listing customers"},{"location":"Lab-MongoDB/Exercise-4/#exercise-4-listing-customers","text":"You can earn 4 points with the completion of this exercise. We will list the customers in this exercise, along with the cumulative value of their orders. This will be similar to exercise 2: we will use aggregation and merging in C# code. The method to implement is IList<Customer> ListCustomers() . The method shall return every customer. The properties of Model.Customer are: Name : the name of the customer ZipCode , City , Street : the address fields of the main site of the customer TotalOrders : the cumulative total of all orders of the customer. You have to aggregate the price*amount for each order of a customer to get this total. If a particular customer has no orders, this value shall be null . Follow these steps to solve this exercise: Create and initialize the customerCollection . List all customers. The customer entity has the list of Sites ; the main site is the item MainSiteID points to. Use this value to find the main in among the list. In the collection of the orders, use an aggregation pipeline to calculate the total of all orders for each CustomerID . Finally, you need the \"merge\" the two result sets. Every customer has a main site; however, not all of them have orders (in which case TotalOrders shall be null ). Use the Customers link of the website to test your solution. This will list the data provided by your code in a tabular format. You can use the Add new order functionality from before to create new orders. This must result in an increase in the total for one of the customers. SUBMISSION Create a screenshot of the web page listing the customers. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall display the list of customers . Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 4: Listing customers"},{"location":"Lab-MongoDB/Exercise-5/","text":"Exercise 5: Optional exercise \u00b6 You can earn an additional +3 points with the completion of this exercise. (In the evaluation, you will see the text \"imsc\" in the exercise title; this is meant for the Hungarian students. Please ignore that.) We will group the orders in this exercise by date. We would like to see how our company performs by comparing the sales across time. We will use a $bucket aggregation. Requirements \u00b6 The method to implement is OrderGroups GroupOrders(int groupsCount) . This operation shall group the orders into groupsCount equal date ranges. The return value contains two values: IList<DateTime> Thresholds : The threshold dates of the date ranges. The lower bound of the interval is inclusive, while the upper bound is exclusive. When having n intervals, the Thresholds list has n + 1 items E.g.: Let the Thresholds be a, b, c, d ; the intervals shall then be: [a, b[ , [b, c[ and [c, d[ . IList<OrderGroup> Groups : The groups that fall into each date range. The properties of OrderGroup are: Date : The start date of the interval. E.g., for the interval [a, b[ the value is a . Pieces : The number of orders within the interval. Total : The cumulative sum of the values of orders within this interval. Further requirements: There should be exactly groupsCount intervals. The number of items in Thresholds will be exactly groupsCount + 1 . The number of items in Groups is at most groupsCount \u2014 no need for an item for intervals with no orders The lower boundary should be the earliest date in the database The upper boundary should be the latest date in the database + 1 hour This is needed because the upper boundary is exclusive. It ensures that every item in the database falls into one of the intervals. Tip: add one hour to a date: date.AddHours(1) . The intervals should be of equal size Tip: C# has built-in support for date arithmetic using dates and the TimeSpan classes. You can assume the following: All orders in the database have Date values even though the type is nullable DateTime? . You can use date.Value to get the date without checking date.HasValue . groupsCount is a positive integer greater than or equal to 1 . Draft solution \u00b6 Get the earliest and latest order dates from the database. Tip: You can execute two queries to get the values or a single aggregation. Calculate the interval boundaries according to the requirements. This will yield the Thresholds list for the return value. Execute a $bucket aggregation on the orders collection. See the documentation here . the groupBy expression will be the date of the order boundaries expects the values as stated in the requirements; the list assembled in the previous step will work just fine output should calculate the count and total value Tip If you receive an error message \"Element '...' does not match any field or property of class...\" then in the output expression, change every property to lowercase (e.g., Pieces -> pieces ). It seems that the Mongo C# driver does not perform the required name transformations here. The $bucket aggregation will yield the intervals according to the specification. You will only need to transform the results into instances of OrderGroup and produce the return value. Use the Group orders link of the website to test your solution. A diagram will display the calculated information. Test your solution by changing the number of groups and adding orders in the past using the previously implemented Add new order functionality. SUBMISSION Create a screenshot of the web page displaying the diagram. Save the screenshot as f5.png and submit it with the other files of the solution. The screenshot shall show both diagrams (you may need to zoom out in the browser to fit them). Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Exercise 5: Optional exercise"},{"location":"Lab-MongoDB/Exercise-5/#exercise-5-optional-exercise","text":"You can earn an additional +3 points with the completion of this exercise. (In the evaluation, you will see the text \"imsc\" in the exercise title; this is meant for the Hungarian students. Please ignore that.) We will group the orders in this exercise by date. We would like to see how our company performs by comparing the sales across time. We will use a $bucket aggregation.","title":"Exercise 5: Optional exercise"},{"location":"Lab-MongoDB/Exercise-5/#requirements","text":"The method to implement is OrderGroups GroupOrders(int groupsCount) . This operation shall group the orders into groupsCount equal date ranges. The return value contains two values: IList<DateTime> Thresholds : The threshold dates of the date ranges. The lower bound of the interval is inclusive, while the upper bound is exclusive. When having n intervals, the Thresholds list has n + 1 items E.g.: Let the Thresholds be a, b, c, d ; the intervals shall then be: [a, b[ , [b, c[ and [c, d[ . IList<OrderGroup> Groups : The groups that fall into each date range. The properties of OrderGroup are: Date : The start date of the interval. E.g., for the interval [a, b[ the value is a . Pieces : The number of orders within the interval. Total : The cumulative sum of the values of orders within this interval. Further requirements: There should be exactly groupsCount intervals. The number of items in Thresholds will be exactly groupsCount + 1 . The number of items in Groups is at most groupsCount \u2014 no need for an item for intervals with no orders The lower boundary should be the earliest date in the database The upper boundary should be the latest date in the database + 1 hour This is needed because the upper boundary is exclusive. It ensures that every item in the database falls into one of the intervals. Tip: add one hour to a date: date.AddHours(1) . The intervals should be of equal size Tip: C# has built-in support for date arithmetic using dates and the TimeSpan classes. You can assume the following: All orders in the database have Date values even though the type is nullable DateTime? . You can use date.Value to get the date without checking date.HasValue . groupsCount is a positive integer greater than or equal to 1 .","title":"Requirements"},{"location":"Lab-MongoDB/Exercise-5/#draft-solution","text":"Get the earliest and latest order dates from the database. Tip: You can execute two queries to get the values or a single aggregation. Calculate the interval boundaries according to the requirements. This will yield the Thresholds list for the return value. Execute a $bucket aggregation on the orders collection. See the documentation here . the groupBy expression will be the date of the order boundaries expects the values as stated in the requirements; the list assembled in the previous step will work just fine output should calculate the count and total value Tip If you receive an error message \"Element '...' does not match any field or property of class...\" then in the output expression, change every property to lowercase (e.g., Pieces -> pieces ). It seems that the Mongo C# driver does not perform the required name transformations here. The $bucket aggregation will yield the intervals according to the specification. You will only need to transform the results into instances of OrderGroup and produce the return value. Use the Group orders link of the website to test your solution. A diagram will display the calculated information. Test your solution by changing the number of groups and adding orders in the past using the previously implemented Add new order functionality. SUBMISSION Create a screenshot of the web page displaying the diagram. Save the screenshot as f5.png and submit it with the other files of the solution. The screenshot shall show both diagrams (you may need to zoom out in the browser to fit them). Verify that your Neptun code is visible on the image at the bottom of the page! The screenshot is required to earn the points.","title":"Draft solution"},{"location":"Lab-QueryOptimization/","text":"Query optimization \u00b6 We will examine the query optimization behavior of Microsoft SQL Server. To properly understand the optimizer's behavior, in the first 5 exercises , we will explain the queries and the behavior too. The rest of the exercises is individual work where it is your task to infer the reason for a specific plan. Your task is to document the behavior and submit the documentation of all exercises. Pre-requisites and preparation \u00b6 Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. Microsoft SQL Server The free Express version is sufficient, or you may also use localdb installed with Visual Studio A Linux version is also available. On macOS, you can use Docker. Visual Studio Code or any other tool for writing markdown SQL Server Management Studio , or you may also use the platform-independent Azure Data Studio is Database initialization script: mssql.sql GitHub account and a git client Materials for preparing for this laboratory: Markdown introduction and detailed documentation Using Microsoft SQL Server: description and video The schema of the database Microsoft SQL Server query optimization Check the materials of Data-driven systems Initial steps \u00b6 Keep in mind that you are expected to follow the submission process . Create and check out your Git repository \u00b6 Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file. Open the markdown file \u00b6 Create the documentation in a markdown file. Open the checked-out git repository with a markdown editor. We recommend using Visual Studio Code: Start VS Code. Use File > Open Folder... to open the git repository folder. In the folder structure on the left, find README.md and double click to open. Edit this file. When you create a screenshot, put the file in this directory next to the other files. This will enable you to use the file name to include the image. File name: lowercase English alphabet only You should avoid using special characters in the file names. Best if you use the English alphabet and no spaces either. The various platforms and git handle filenames differently. GitHub's web interface will only render the documentation with the images correctly if you only use all lowercase filenames with the English alphabet and no spaces. For convenient editing open the preview ( Ctrl-K + V ). Alternative editor If you do not like VS code, you can also use the GitHub web interface to edit the markdown; you also have a preview here. File upload will be trickier. Create the database \u00b6 Connect to Microsoft SQL Server using SQL Server Management Studio. Start Management Studio and use the following connection details: Server name: (localdb)\\mssqllocaldb or .\\sqlexpress (which is short for: localhost\\sqlexpress ) Authentication: Windows authentication Create a new database (if it does not exist yet). The name should be your Neptun code: in Object Explorer right-click Databases and choose Create Database . Create the sample database by executing the initializer script Open a new Query window, paste the script into the window, then execute it. Make sure to select the correct database in the toolbar dropdown. Verify that the tables are created. If the Tables folder was open before, you need to refresh it. . Getting the actual execution plan \u00b6 If you are not using Windows We are primarily using SQL Server Management Studio to get the execution plans. If you are not using Windows, you can also use Azure Data Studio-t to obtain the query plan . We will check the query plan the optimizer chose and the server executed in the following exercises. In SQL Server Management Studio, open the Query menu and check Include Actual Execution Plan . The plan will be displayed after the query is completed at the bottom of the window on the Execution plan pane. The plan is a data flow diagram where the query execution is the flow of the data. The items are the individual steps, and the percentages are the relative cost of each step with regards to the whole query.","title":"Query optimization"},{"location":"Lab-QueryOptimization/#query-optimization","text":"We will examine the query optimization behavior of Microsoft SQL Server. To properly understand the optimizer's behavior, in the first 5 exercises , we will explain the queries and the behavior too. The rest of the exercises is individual work where it is your task to infer the reason for a specific plan. Your task is to document the behavior and submit the documentation of all exercises.","title":"Query optimization"},{"location":"Lab-QueryOptimization/#pre-requisites-and-preparation","text":"Required tools to complete the tasks: Windows, Linux, or macOS: All tools are platform-independent, or a platform-independent alternative is available. Microsoft SQL Server The free Express version is sufficient, or you may also use localdb installed with Visual Studio A Linux version is also available. On macOS, you can use Docker. Visual Studio Code or any other tool for writing markdown SQL Server Management Studio , or you may also use the platform-independent Azure Data Studio is Database initialization script: mssql.sql GitHub account and a git client Materials for preparing for this laboratory: Markdown introduction and detailed documentation Using Microsoft SQL Server: description and video The schema of the database Microsoft SQL Server query optimization Check the materials of Data-driven systems","title":"Pre-requisites and preparation"},{"location":"Lab-QueryOptimization/#initial-steps","text":"Keep in mind that you are expected to follow the submission process .","title":"Initial steps"},{"location":"Lab-QueryOptimization/#create-and-check-out-your-git-repository","text":"Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file.","title":"Create and check out your Git repository"},{"location":"Lab-QueryOptimization/#open-the-markdown-file","text":"Create the documentation in a markdown file. Open the checked-out git repository with a markdown editor. We recommend using Visual Studio Code: Start VS Code. Use File > Open Folder... to open the git repository folder. In the folder structure on the left, find README.md and double click to open. Edit this file. When you create a screenshot, put the file in this directory next to the other files. This will enable you to use the file name to include the image. File name: lowercase English alphabet only You should avoid using special characters in the file names. Best if you use the English alphabet and no spaces either. The various platforms and git handle filenames differently. GitHub's web interface will only render the documentation with the images correctly if you only use all lowercase filenames with the English alphabet and no spaces. For convenient editing open the preview ( Ctrl-K + V ). Alternative editor If you do not like VS code, you can also use the GitHub web interface to edit the markdown; you also have a preview here. File upload will be trickier.","title":"Open the markdown file"},{"location":"Lab-QueryOptimization/#create-the-database","text":"Connect to Microsoft SQL Server using SQL Server Management Studio. Start Management Studio and use the following connection details: Server name: (localdb)\\mssqllocaldb or .\\sqlexpress (which is short for: localhost\\sqlexpress ) Authentication: Windows authentication Create a new database (if it does not exist yet). The name should be your Neptun code: in Object Explorer right-click Databases and choose Create Database . Create the sample database by executing the initializer script Open a new Query window, paste the script into the window, then execute it. Make sure to select the correct database in the toolbar dropdown. Verify that the tables are created. If the Tables folder was open before, you need to refresh it. .","title":"Create the database"},{"location":"Lab-QueryOptimization/#getting-the-actual-execution-plan","text":"If you are not using Windows We are primarily using SQL Server Management Studio to get the execution plans. If you are not using Windows, you can also use Azure Data Studio-t to obtain the query plan . We will check the query plan the optimizer chose and the server executed in the following exercises. In SQL Server Management Studio, open the Query menu and check Include Actual Execution Plan . The plan will be displayed after the query is completed at the bottom of the window on the Execution plan pane. The plan is a data flow diagram where the query execution is the flow of the data. The items are the individual steps, and the percentages are the relative cost of each step with regards to the whole query.","title":"Getting the actual execution plan"},{"location":"Lab-QueryOptimization/Exercise-1/","text":"Exercises solved together \u00b6 SUBMISSION The submission shall be a documentation written in the README.md file: document the SQL commands (if the exercise tells you to), a screenshot of the query plan (just the plan and not the entire desktop!), and an explanation: what do you see on the query plan and why the system chose this option. The documentation should correctly display with the images in the web interface of GitHub! You need to verify this during the submission: open the repository in the browser and switch to your branch; GitHub will automatically render the README.md file with the images. Submit your own work Even though the solutions are provided below, you are required to execute the queries, get the execution plan, think about it, and document it with your own words. Copying the explanations from below is not acceptable! If the query plan or the explanation of subsequent exercises is the same, or at least very similar, it is enough to document everything once (one screenshot and one reasoning); and list which (sub)exercises it is the solution for. Exercise 1 (2p) \u00b6 Drop the CustomerSite => Customer foreign key and the Customer table primary key constraint. Find these in the Object Explorer and delete them (the PK... is the primary key while the FK... is the foreign key - the ones you need to delete are in two different tables!): Execute the following queries on the Customer table and examine the execution plans (always fetch the entire records using select * ): a) query the whole table b) get one record based on primary key c) querying records where the primary key is not a specified constant (use the <> comparison operation for not equals) d) querying records where the primary key is greater than a specified constant e) querying records where the primary key is greater than a specified constant, ordering by ID descending Document the SQL commands you used and explain the actual query execution plan! Solution The SQL queries : a) select * from customer b) select * from customer where id = 1 c) select * from customer where id <> 1 d) select * from customer where id > 1 e) select * from customer where id > 1 order by id desc a)-d) The execution plan is indentical for all, it uses a table scan each time: Explanation : the optimizer cannot use any index, as there is none. Thus there is no other choice but to use a table scan . e) This one is a little different due to the order by there is a sort stage too. Explanation : The table scan is the same, and after that, there is still a need for sorting - without any index, it is a separate stage. Exercise 2 (2p) \u00b6 Re-create the primary key of the Customer table: Right-click the table > Design > then right-click the ID column \"Set Primary Key \" then Save, or execute ALTER TABLE [dbo].[Customer] ADD PRIMARY KEY CLUSTERED ([ID] ASC) Re-run the same queries as in the previous exercise. What do you experience? Solution The commands are the same as before. a) The Clustered Index Scan iterates the table. We have a Clustered Index automatically created for the primary key, which has the records sorted by ID. By iterating through this index, all records are visited. This is almost identical to a Table Scan, though, not efficient. However, this is what we asked for here. b) A Clustered Index Seek is enough. Since the filter criteria is for the ID, for which there is an index available, the matching record can be found quickly. This is an efficient plan; the Clustered Index is used for the exact purpose we created it for. c) Similar to the previous one, a Clustered Index Seek between two intervals ( < constant , > constant ). Since the filter criteria still references the ID field with a Clustered Index, the query will use this index. This is an efficient query. d) Very similar to the previous one with a range filter. e) Clustered Index Seek with a backward seek order. The Properties window shows the Seek Order-t: find the last matching record, and walk the index backward, which will yield a sorted result set. Exercise 3 (2p) \u00b6 Execute the following queries on the Product table. f) query the whole table g) search for specific records where Price equals a value h) query records where Price is not a specified constant (<>) i) query records where Price is greater than a value j) query records where Price is greater than a value, ordered by Price descending Document the SQL commands you used and explain the actual query execution plan! Solution The SQL commands : f) select * from product g) select * from product where price = 800 h) select * from product where price <> 800 i) select * from product where price > 800 j) select * from product where price > 800 order by price desc f)-i) A Clustered Index Scan iterates through the contents of the index. This is still equal to reading the entire table since there is no index to match the filter criteria. Although a Clustered Index is used, it does not serve any purpose in filtering; all records are visited, and the filter is evaluated for each. These are not efficient queries, as the existing index is of no use. j) Still a Clustered Index Scan, but what is interesting is that cost of the sorting stage is quite large. Even after executing a costly Index Scan, we still have further sorting to do. A good index would help, but there is no index for the sorted column. Exercise 4 (2p) \u00b6 Add a new non-clustered index on column Price . How do the execution plans change? To add the index use Object Explorer , find the table, expand it, and right-click Indexes -> New index > Non-Clustered Index... Indices should have meaningful names, e.g., IX_Tablename_Fieldname . Add Price column to the Index key columns list. Repeat the queries from the previous exercise and explain the plans! Solution The SQL commands are the same as in the previous exercise. f) Despite the new index, it is still an Index Scan - since we asked for the contents of the entire table. g)-i) Clustered Index Scan iterating through the entire table, just as if there was no index available for the filtered column. Why does it not use the new index? The reason is the projection; that is, we query the entire record. The NonClustered Index could yield a set of record identifiers, after which the records themselves would still need to be queried. The optimizer decides that it is not worth doing so; an Index Scan is more efficient. j) The NonClustered Index Seek yields keys, which are looked up in the Clustered Index, just like joining the two indices. We would have expected something similar in the previous queries too. The Clustered Index is needed as entire records are fetched as the NonClustered Index only provides references. However, these references are in the correct order (the NonClustered Index ensures it); so after the lookup in the Clustered Index, there is no further need to do the sorting. If only the Clustered Index were used (Clustered Index Scan), the sorting would have to be performed in a separate stage. This is an acceptable query, as the NonClustered Index helps in avoiding a costly sorting step. Exercise 5 (2p) \u00b6 Generate new records into the Product table with the script below. How do the execution plans change? When repeating the query for sub-exercise i), choose a constant value that will yield few resulting records, then choose a value that returns almost all records. Explain the differences! SELECT TOP ( 1000000 ) n = ABS ( CHECKSUM ( NEWID ())) INTO dbo . Numbers FROM sys . all_objects AS s1 CROSS JOIN sys . all_objects AS s2 OPTION ( MAXDOP 1 ); CREATE CLUSTERED INDEX n ON dbo . Numbers ( n ) ; INSERT INTO Product ( Name , Price , Stock , VATID , CategoryID ) SELECT 'Apple' , n % 50000 , n % 100 , 3 , 13 FROM Numbers Solution The SQL commands are the same. f) Same as before. g) References from the NonClustered Index Seek are looked up in the Clustered Index, just like joining the two indices. Let us compare this plan to the one from before having a smaller table. Why is the Clustered Index Scan not used now? In the case of larger tables, the selectivity (i.e., how many records match the filtering) is more important, hence the use of the NonClustered Index. The Clustered Index Scan would be too costly in a large table. The NonClustered Index can reduce the number of records, hence its role here. Based on the statistics of the Price column, it can be derived that the = operator will match few records. Important! Just because it is an = comparison, it does not directly follow that there are few matches; imagine the column having the same value in all records. Hence the need for the statistics! This is an acceptable query. Since the filtering reduces the number of records, it is worth using the index. h) Clustered Index Scan as before. Why the difference compared to the previous case? If the = operator yields few matches, then <> will yield many. This is derived from the statistics too. So no use in doing the same as in the previous case; a Clustered Index Scan is probably more efficient. i) The plan depends on the constant. If it yields few matches, similar to g); otherwise the same as in h). j) Just like for g). Does the order by desc matter here? The optimizer tries to avoid sorting, and this is the only way to do so. This is an acceptable plan; by using the NonClustered Index there is no separate sorting stage.","title":"Exercises solved together"},{"location":"Lab-QueryOptimization/Exercise-1/#exercises-solved-together","text":"SUBMISSION The submission shall be a documentation written in the README.md file: document the SQL commands (if the exercise tells you to), a screenshot of the query plan (just the plan and not the entire desktop!), and an explanation: what do you see on the query plan and why the system chose this option. The documentation should correctly display with the images in the web interface of GitHub! You need to verify this during the submission: open the repository in the browser and switch to your branch; GitHub will automatically render the README.md file with the images. Submit your own work Even though the solutions are provided below, you are required to execute the queries, get the execution plan, think about it, and document it with your own words. Copying the explanations from below is not acceptable! If the query plan or the explanation of subsequent exercises is the same, or at least very similar, it is enough to document everything once (one screenshot and one reasoning); and list which (sub)exercises it is the solution for.","title":"Exercises solved together"},{"location":"Lab-QueryOptimization/Exercise-1/#exercise-1-2p","text":"Drop the CustomerSite => Customer foreign key and the Customer table primary key constraint. Find these in the Object Explorer and delete them (the PK... is the primary key while the FK... is the foreign key - the ones you need to delete are in two different tables!): Execute the following queries on the Customer table and examine the execution plans (always fetch the entire records using select * ): a) query the whole table b) get one record based on primary key c) querying records where the primary key is not a specified constant (use the <> comparison operation for not equals) d) querying records where the primary key is greater than a specified constant e) querying records where the primary key is greater than a specified constant, ordering by ID descending Document the SQL commands you used and explain the actual query execution plan! Solution The SQL queries : a) select * from customer b) select * from customer where id = 1 c) select * from customer where id <> 1 d) select * from customer where id > 1 e) select * from customer where id > 1 order by id desc a)-d) The execution plan is indentical for all, it uses a table scan each time: Explanation : the optimizer cannot use any index, as there is none. Thus there is no other choice but to use a table scan . e) This one is a little different due to the order by there is a sort stage too. Explanation : The table scan is the same, and after that, there is still a need for sorting - without any index, it is a separate stage.","title":"Exercise 1 (2p)"},{"location":"Lab-QueryOptimization/Exercise-1/#exercise-2-2p","text":"Re-create the primary key of the Customer table: Right-click the table > Design > then right-click the ID column \"Set Primary Key \" then Save, or execute ALTER TABLE [dbo].[Customer] ADD PRIMARY KEY CLUSTERED ([ID] ASC) Re-run the same queries as in the previous exercise. What do you experience? Solution The commands are the same as before. a) The Clustered Index Scan iterates the table. We have a Clustered Index automatically created for the primary key, which has the records sorted by ID. By iterating through this index, all records are visited. This is almost identical to a Table Scan, though, not efficient. However, this is what we asked for here. b) A Clustered Index Seek is enough. Since the filter criteria is for the ID, for which there is an index available, the matching record can be found quickly. This is an efficient plan; the Clustered Index is used for the exact purpose we created it for. c) Similar to the previous one, a Clustered Index Seek between two intervals ( < constant , > constant ). Since the filter criteria still references the ID field with a Clustered Index, the query will use this index. This is an efficient query. d) Very similar to the previous one with a range filter. e) Clustered Index Seek with a backward seek order. The Properties window shows the Seek Order-t: find the last matching record, and walk the index backward, which will yield a sorted result set.","title":"Exercise 2 (2p)"},{"location":"Lab-QueryOptimization/Exercise-1/#exercise-3-2p","text":"Execute the following queries on the Product table. f) query the whole table g) search for specific records where Price equals a value h) query records where Price is not a specified constant (<>) i) query records where Price is greater than a value j) query records where Price is greater than a value, ordered by Price descending Document the SQL commands you used and explain the actual query execution plan! Solution The SQL commands : f) select * from product g) select * from product where price = 800 h) select * from product where price <> 800 i) select * from product where price > 800 j) select * from product where price > 800 order by price desc f)-i) A Clustered Index Scan iterates through the contents of the index. This is still equal to reading the entire table since there is no index to match the filter criteria. Although a Clustered Index is used, it does not serve any purpose in filtering; all records are visited, and the filter is evaluated for each. These are not efficient queries, as the existing index is of no use. j) Still a Clustered Index Scan, but what is interesting is that cost of the sorting stage is quite large. Even after executing a costly Index Scan, we still have further sorting to do. A good index would help, but there is no index for the sorted column.","title":"Exercise 3 (2p)"},{"location":"Lab-QueryOptimization/Exercise-1/#exercise-4-2p","text":"Add a new non-clustered index on column Price . How do the execution plans change? To add the index use Object Explorer , find the table, expand it, and right-click Indexes -> New index > Non-Clustered Index... Indices should have meaningful names, e.g., IX_Tablename_Fieldname . Add Price column to the Index key columns list. Repeat the queries from the previous exercise and explain the plans! Solution The SQL commands are the same as in the previous exercise. f) Despite the new index, it is still an Index Scan - since we asked for the contents of the entire table. g)-i) Clustered Index Scan iterating through the entire table, just as if there was no index available for the filtered column. Why does it not use the new index? The reason is the projection; that is, we query the entire record. The NonClustered Index could yield a set of record identifiers, after which the records themselves would still need to be queried. The optimizer decides that it is not worth doing so; an Index Scan is more efficient. j) The NonClustered Index Seek yields keys, which are looked up in the Clustered Index, just like joining the two indices. We would have expected something similar in the previous queries too. The Clustered Index is needed as entire records are fetched as the NonClustered Index only provides references. However, these references are in the correct order (the NonClustered Index ensures it); so after the lookup in the Clustered Index, there is no further need to do the sorting. If only the Clustered Index were used (Clustered Index Scan), the sorting would have to be performed in a separate stage. This is an acceptable query, as the NonClustered Index helps in avoiding a costly sorting step.","title":"Exercise 4 (2p)"},{"location":"Lab-QueryOptimization/Exercise-1/#exercise-5-2p","text":"Generate new records into the Product table with the script below. How do the execution plans change? When repeating the query for sub-exercise i), choose a constant value that will yield few resulting records, then choose a value that returns almost all records. Explain the differences! SELECT TOP ( 1000000 ) n = ABS ( CHECKSUM ( NEWID ())) INTO dbo . Numbers FROM sys . all_objects AS s1 CROSS JOIN sys . all_objects AS s2 OPTION ( MAXDOP 1 ); CREATE CLUSTERED INDEX n ON dbo . Numbers ( n ) ; INSERT INTO Product ( Name , Price , Stock , VATID , CategoryID ) SELECT 'Apple' , n % 50000 , n % 100 , 3 , 13 FROM Numbers Solution The SQL commands are the same. f) Same as before. g) References from the NonClustered Index Seek are looked up in the Clustered Index, just like joining the two indices. Let us compare this plan to the one from before having a smaller table. Why is the Clustered Index Scan not used now? In the case of larger tables, the selectivity (i.e., how many records match the filtering) is more important, hence the use of the NonClustered Index. The Clustered Index Scan would be too costly in a large table. The NonClustered Index can reduce the number of records, hence its role here. Based on the statistics of the Price column, it can be derived that the = operator will match few records. Important! Just because it is an = comparison, it does not directly follow that there are few matches; imagine the column having the same value in all records. Hence the need for the statistics! This is an acceptable query. Since the filtering reduces the number of records, it is worth using the index. h) Clustered Index Scan as before. Why the difference compared to the previous case? If the = operator yields few matches, then <> will yield many. This is derived from the statistics too. So no use in doing the same as in the previous case; a Clustered Index Scan is probably more efficient. i) The plan depends on the constant. If it yields few matches, similar to g); otherwise the same as in h). j) Just like for g). Does the order by desc matter here? The optimizer tries to avoid sorting, and this is the only way to do so. This is an acceptable plan; by using the NonClustered Index there is no separate sorting stage.","title":"Exercise 5 (2p)"},{"location":"Lab-QueryOptimization/Exercise-2/","text":"Individual exercises \u00b6 SUBMISSION Continue documenting the results the same way. Keep in mind that the documentation should correctly display with the images in the web interface of GitHub! You need to verify this during the submission: open the repository in the browser and switch to your branch; GitHub will automatically render the README.md file with the images. Exercise 6 (1p) \u00b6 Repeat the queries on the Product table, but instead of fetching the entire record, only get the ID and the Price columns. How do the execution plans change? Explain the differences! Exercise 7 (1p) \u00b6 Analyze the following queries executed on the Product table: k) query records where the primary key is between two values (use the BETWEEN operator) l) query records where the primary key is between two values (use the BETWEEN operator), or it is equal to a value that falls outside of this range Document the SQL commands you used and explain the actual query execution plan! Exercise 8 (1p) \u00b6 In exercise 6, WHERE Price= compared an integer and a floating-point number. Let us experiment with other comparisons: query records from the Product table with the following filter criteria. m) where cast(Price as int) = integer number n) where Price BETWEEN integer number-0.0001 AND integer number+0.0001 Choose a random integer number in these queries and fetch only the primary key . Analyze the execution plans. Exercise 9 (1p) \u00b6 Analyze the following queries execute on the Product table: o) query entire records where Price is less than a constant value (the filter should yield few matches), ordered by ID descending p) the same, but fetch only ID and Price q) query entire records where Price is greater than a constant value (the filter should yield many matches), ordered by ID descending r) the same, but fetch only ID and Price Document the SQL commands you used and explain the actual query execution plan! Exercise 10 (1p) \u00b6 Create a new index for the Name column and analyze the following queries executed on the Product table: s) query names and IDs where the name begins with B - use function SUBSTRING t) the same, but now using LIKE u) query names and IDs where the name contains a B (LIKE) v) query the ID of a product where the name equals (=) a string w) the same, but now compare case-insensitively using UPPER Document the SQL commands you used and explain the actual query execution plan! Exercise 11 (1p) \u00b6 Analyze the following queries executed on the Product table: x) get the maximum of Id y) get the minimum of Price Document the SQL commands you used and explain the actual query execution plan! Exercise 12 (1p) \u00b6 Query the number of products per category ( CategoryId ). Document the SQL commands you used and explain the actual query execution plan! Exercise 13 (1p) \u00b6 How could we improve on the performance of the previous query? Explain and implement the solution and repeat the previous query. Tip You need to add a new index. The question is: to which column? Exercise 14 (1p) \u00b6 List the Name of each Product where CategoryId equals 2. Document the SQL commands you used and explain the actual query execution plan! Explain whether the index added in the previous exercises helps the performance. Exercise 15 (1p) \u00b6 Improve the performance of the previous query. Extend the index added before by including the name: right-click the index -> Properties -> and add Name to Included columns . Repeat the previous query and analyze the plan.","title":"Individual exercises"},{"location":"Lab-QueryOptimization/Exercise-2/#individual-exercises","text":"SUBMISSION Continue documenting the results the same way. Keep in mind that the documentation should correctly display with the images in the web interface of GitHub! You need to verify this during the submission: open the repository in the browser and switch to your branch; GitHub will automatically render the README.md file with the images.","title":"Individual exercises"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-6-1p","text":"Repeat the queries on the Product table, but instead of fetching the entire record, only get the ID and the Price columns. How do the execution plans change? Explain the differences!","title":"Exercise 6 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-7-1p","text":"Analyze the following queries executed on the Product table: k) query records where the primary key is between two values (use the BETWEEN operator) l) query records where the primary key is between two values (use the BETWEEN operator), or it is equal to a value that falls outside of this range Document the SQL commands you used and explain the actual query execution plan!","title":"Exercise 7 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-8-1p","text":"In exercise 6, WHERE Price= compared an integer and a floating-point number. Let us experiment with other comparisons: query records from the Product table with the following filter criteria. m) where cast(Price as int) = integer number n) where Price BETWEEN integer number-0.0001 AND integer number+0.0001 Choose a random integer number in these queries and fetch only the primary key . Analyze the execution plans.","title":"Exercise 8 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-9-1p","text":"Analyze the following queries execute on the Product table: o) query entire records where Price is less than a constant value (the filter should yield few matches), ordered by ID descending p) the same, but fetch only ID and Price q) query entire records where Price is greater than a constant value (the filter should yield many matches), ordered by ID descending r) the same, but fetch only ID and Price Document the SQL commands you used and explain the actual query execution plan!","title":"Exercise 9 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-10-1p","text":"Create a new index for the Name column and analyze the following queries executed on the Product table: s) query names and IDs where the name begins with B - use function SUBSTRING t) the same, but now using LIKE u) query names and IDs where the name contains a B (LIKE) v) query the ID of a product where the name equals (=) a string w) the same, but now compare case-insensitively using UPPER Document the SQL commands you used and explain the actual query execution plan!","title":"Exercise 10 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-11-1p","text":"Analyze the following queries executed on the Product table: x) get the maximum of Id y) get the minimum of Price Document the SQL commands you used and explain the actual query execution plan!","title":"Exercise 11 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-12-1p","text":"Query the number of products per category ( CategoryId ). Document the SQL commands you used and explain the actual query execution plan!","title":"Exercise 12 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-13-1p","text":"How could we improve on the performance of the previous query? Explain and implement the solution and repeat the previous query. Tip You need to add a new index. The question is: to which column?","title":"Exercise 13 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-14-1p","text":"List the Name of each Product where CategoryId equals 2. Document the SQL commands you used and explain the actual query execution plan! Explain whether the index added in the previous exercises helps the performance.","title":"Exercise 14 (1p)"},{"location":"Lab-QueryOptimization/Exercise-2/#exercise-15-1p","text":"Improve the performance of the previous query. Extend the index added before by including the name: right-click the index -> Properties -> and add Name to Included columns . Repeat the previous query and analyze the plan.","title":"Exercise 15 (1p)"},{"location":"Lab-QueryOptimization/Exercise-3/","text":"Optional exercises \u00b6 You can earn an additional +3 points with the completion of this exercise. Exercise 16 \u00b6 Compare the following Invoice - InvoiceItem query: for each invoice item get the customer name. SELECT CustomerName , Name FROM Invoice JOIN InvoiceItem ON Invoice . ID = InvoiceItem . InvoiceID Which join strategy was chosen? Explain why the system chose it! Exercise 17 \u00b6 Compare the various JOIN strategies when querying all Product - Category record pairs. Tip Use query hints or the option command to explicitly specify the join strategy. Put the 3 queries (each with a different join strategy) into one execution unit (execute them together). This will give you the relative cost of each option. Document the SQL commands you used and explain the actual query execution plan!","title":"Optional exercises"},{"location":"Lab-QueryOptimization/Exercise-3/#optional-exercises","text":"You can earn an additional +3 points with the completion of this exercise.","title":"Optional exercises"},{"location":"Lab-QueryOptimization/Exercise-3/#exercise-16","text":"Compare the following Invoice - InvoiceItem query: for each invoice item get the customer name. SELECT CustomerName , Name FROM Invoice JOIN InvoiceItem ON Invoice . ID = InvoiceItem . InvoiceID Which join strategy was chosen? Explain why the system chose it!","title":"Exercise 16"},{"location":"Lab-QueryOptimization/Exercise-3/#exercise-17","text":"Compare the various JOIN strategies when querying all Product - Category record pairs. Tip Use query hints or the option command to explicitly specify the join strategy. Put the 3 queries (each with a different join strategy) into one execution unit (execute them together). This will give you the relative cost of each option. Document the SQL commands you used and explain the actual query execution plan!","title":"Exercise 17"},{"location":"Lab-ReportingServices/","text":"Reporting Services \u00b6 In this lab, we will work with Microsoft SQL Server Reporting Services , a tool we have not seen before. We will start working together, then some of the exercises will be individual work. You shall submit the solution to all exercises. Pre-requisites and preparation \u00b6 Required tools to complete the tasks: A PC with Windows. Microsoft SQL Server: The free Express version is sufficient, or you may also use localdb installed with Visual Studio SQL Server Management Studio Database initialization script: adventure-works-2014-oltp-script.zip Microsoft Visual Studio 2019 (2022 does not work here): The free Community edition is sufficient Report Server Project support for Visual Studio: Microsoft Reporting Services Projects extension (Keep the extension up to date .) GitHub account and a git client Materials for preparing for this laboratory: Using Microsoft SQL Server: description and video SQL Reporting Services official tutorial Initial steps \u00b6 Keep in mind that you are expected to follow the submission process . Create and check out your Git repository \u00b6 Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file. Create the Adventure Works 2014 database \u00b6 We will work with the Adventure Works sample database. This database contains the operational information of a fictional retail company. Instead of understanding the database contents, we will use a few predefined queries that list product purchases. Download adventure-works-2014-oltp-script.zip and extract it to folder C:\\work\\Adventure Works 2014 OLTP Script (create the folder if it does not exist yet). The folder name should be as above; otherwise, you need to change the path in the sql script: -- NOTE: Change this path if you copied the script source to another path : setvar SqlSamplesSourceDataPath \"C:\\work\\Adventure Works 2014 OLTP Script\\\" If you need to edit the path, make sure to keep the trailing slash! Connect to Microsoft SQL Server using SQL Server Management Studio. Use the following connection details. Server name: (localdb)\\mssqllocaldb when using LocalDB, or localhost\\sqlexpress when using SQL Express Authentication: Windows authentication Use File / Open / File... to open instawdb.sql from the folder created above. Do not execute it yet! First, you should turn on SQLCMD mode: in the Query menu click SQLCMD Mode ; then click Execute . Verify whether the database and its contents are created. Select Databases in the Object explorer on the left and click Refresh . The AdventureWorks2014 database shall appear with a number of tables inside. . Open a new SQL Query window on this database (right-click the database and choose New query ), and execute the following script with your own Neptun code substituted: update Production . Product set Name = 'NEPTUN' + Name Check the contents of the table Production.Product and verify if it has your Neptun code in the product names: right-click the table and choose Select top 1000 rows . IMPORTANT Your Neptun code must be listed in the names. You will need to create screenshots in the following exercises, and your Neptun code must appear on these images.","title":"Reporting Services"},{"location":"Lab-ReportingServices/#reporting-services","text":"In this lab, we will work with Microsoft SQL Server Reporting Services , a tool we have not seen before. We will start working together, then some of the exercises will be individual work. You shall submit the solution to all exercises.","title":"Reporting Services"},{"location":"Lab-ReportingServices/#pre-requisites-and-preparation","text":"Required tools to complete the tasks: A PC with Windows. Microsoft SQL Server: The free Express version is sufficient, or you may also use localdb installed with Visual Studio SQL Server Management Studio Database initialization script: adventure-works-2014-oltp-script.zip Microsoft Visual Studio 2019 (2022 does not work here): The free Community edition is sufficient Report Server Project support for Visual Studio: Microsoft Reporting Services Projects extension (Keep the extension up to date .) GitHub account and a git client Materials for preparing for this laboratory: Using Microsoft SQL Server: description and video SQL Reporting Services official tutorial","title":"Pre-requisites and preparation"},{"location":"Lab-ReportingServices/#initial-steps","text":"Keep in mind that you are expected to follow the submission process .","title":"Initial steps"},{"location":"Lab-ReportingServices/#create-and-check-out-your-git-repository","text":"Create your git repository using the invitation link in Moodle. Each lab has a different URL; make sure to use the right one! Wait for the repository creation to complete, then check out the repository. If you are not asked for credentials to log in to GitHub in university computer laboratories when checking out the repository, the operation may fail. This is likely due to the machine using someone else's GitHub credentials. Delete these credentials first (see here ), then retry the checkout. Create a new branch with the name solution and work on this branch. Open the checked-out folder and type your Neptun code into the neptun.txt file. There should be a single line with the 6 characters of your Neptun code and nothing else in this file.","title":"Create and check out your Git repository"},{"location":"Lab-ReportingServices/#create-the-adventure-works-2014-database","text":"We will work with the Adventure Works sample database. This database contains the operational information of a fictional retail company. Instead of understanding the database contents, we will use a few predefined queries that list product purchases. Download adventure-works-2014-oltp-script.zip and extract it to folder C:\\work\\Adventure Works 2014 OLTP Script (create the folder if it does not exist yet). The folder name should be as above; otherwise, you need to change the path in the sql script: -- NOTE: Change this path if you copied the script source to another path : setvar SqlSamplesSourceDataPath \"C:\\work\\Adventure Works 2014 OLTP Script\\\" If you need to edit the path, make sure to keep the trailing slash! Connect to Microsoft SQL Server using SQL Server Management Studio. Use the following connection details. Server name: (localdb)\\mssqllocaldb when using LocalDB, or localhost\\sqlexpress when using SQL Express Authentication: Windows authentication Use File / Open / File... to open instawdb.sql from the folder created above. Do not execute it yet! First, you should turn on SQLCMD mode: in the Query menu click SQLCMD Mode ; then click Execute . Verify whether the database and its contents are created. Select Databases in the Object explorer on the left and click Refresh . The AdventureWorks2014 database shall appear with a number of tables inside. . Open a new SQL Query window on this database (right-click the database and choose New query ), and execute the following script with your own Neptun code substituted: update Production . Product set Name = 'NEPTUN' + Name Check the contents of the table Production.Product and verify if it has your Neptun code in the product names: right-click the table and choose Select top 1000 rows . IMPORTANT Your Neptun code must be listed in the names. You will need to create screenshots in the following exercises, and your Neptun code must appear on these images.","title":"Create the Adventure Works 2014 database"},{"location":"Lab-ReportingServices/Exercise-1/","text":"Exercise 1: Table report \u00b6 This exercise is solved together with the lab instructor. In the checked-out repository, locate file reportserver.sln and open it with Visual Studio. This is an empty Report Server project. The Report Server project consists mainly of Report Definition (.rdl) files, that define the data sources (queries) and a template, which, when rendered, produces the final result: a report. These reports can be installed to a Report Server and executed there, providing the users with up-to-date data. In this lab, we will not use the Report Server. This is mainly because the configuration would require administrative privileges that we do not have in the labs. Therefore, we will preview the reports in Visual Studio. Create the first Report Definition file \u00b6 In the Solution Explorer right-click Reports and choose Add > New Item . Choose the Report type from among the listed templates. Call it Sales Orders.rdl , then click Add. If adding the new report file fails In certain Visual Studio and Report Server project versions adding this new report file might fail. If this happens, follow these steps instead. Download this empty rdl file . Save the file with the correct name to the reportserver folder of your repository (this folder already exist). In Visual Studio right-click Reports then choose Add > Existing Item , and browse for this file. Open the report file to get the Report Designer view. Here, the new .rdl file is displayed in the Design view. This is our development view. The Report Designer has two views: Design and Preview . A panel called Report Data (on the left) is also opened. Here, we can define data sources. If the data sources are set, we can create the report on the Design tab and check how it would look like on the Preview tab. Configuring the data source \u00b6 A data source defines where our data comes from. This will be the SQL Server database created before. Using the Report Data pane, click New > Data Source . The name shall be \"AdventureWorks2014\". Choose Microsoft SQL Server as the connection type and click the button to the right of connection string to configure the database access Server name: (localdb)\\mssqllocaldb Authentication: Windows Authentication Select or enter database name: AdventureWorks2014 Click OK to close the dialog. Then re-open the Data Source settings from the Report Data panel by right-clicking on the newly created data source, opening its properties, and then going to the Credentials page. The following checkbox has to be checked: Configuring a data set \u00b6 The next step is the configuration of a dataset. Practically, this means executing a query in the database. Using the Report Data pane, click New > Data Set . Call the dataset \"AdventureWorksDataset\". Select the data source created before from the dropdown, then apply the following settings: Copy the following query. SELECT soh . OrderDate AS [ Date ], soh . SalesOrderNumber AS [ Order ], pps . Name AS Subcat , pp . Name as Product , SUM ( sd . OrderQty ) AS Qty , SUM ( sd . LineTotal ) AS LineTotal FROM Sales . SalesPerson sp INNER JOIN Sales . SalesOrderHeader AS soh ON sp . BusinessEntityID = soh . SalesPersonID INNER JOIN Sales . SalesOrderDetail AS sd ON sd . SalesOrderID = soh . SalesOrderID INNER JOIN Production . Product AS pp ON sd . ProductID = pp . ProductID INNER JOIN Production . ProductSubcategory AS pps ON pp . ProductSubcategoryID = pps . ProductSubcategoryID INNER JOIN Production . ProductCategory AS ppc ON ppc . ProductCategoryID = pps . ProductCategoryID GROUP BY ppc . Name , soh . OrderDate , soh . SalesOrderNumber , pps . Name , pp . Name , soh . SalesPersonID HAVING ppc . Name = 'Clothing' Click Refresh fields when ready. We have a Query Designer where the query can be created with visual aids. We will not use it, but it is available. Click OK to close the dialog. Table report (5p) \u00b6 Now that we have our connection to the database and the query that will supply the data, let us create a report. A report is basically data from the database displayed in a table or with diagrams. Open the Toolbox pane. You can do this from the View menu. From the Toolbox choose Table and draw a table on the big, empty and white canvas on the Design tab: Switch back to the Report Data pane and expand the AdventureWorksDataset: If the node is empty or cannot be opened, you need to re-open the data set properties using right-click, then clicking the Refresh Fields button. Drag the Date field to the first column of the table. It should look like this: The [Date] in the second row shows the expression to evaluate, while \"Date\" in the first row is the literal header label - we can change it too. Similarly, add Order and Product to the second and third columns. Add Qty as well: drag it to the right side of the last column; the cursor icon will change to + sign, and a blue line at the end of the table will appear. This will add a new fourth column. Add LineTotal similarly into the fifth column. The first report is almost ready. Let us check how it looks like using the Preview tab. Note that it might take a while for it to open the first time. It will be faster the second time. Verify that your Neptun code appears in the table content! (If not, you forgot a preparation step. Go back, and repeat the steps!) We can print or export the report into various formats (e.g., Word, Excel, PDF). However, this report is not very pretty, e.g., the currency is not displayed, and the Qty and date columns are not formatted, etc. Go back to Design tab, right-click the [Date] expression, and select Text Box Properties. Navigate to the Number page, select the Date category , and choose a date format you like. Right-click [LineTotal] , use Text Box Properties again, and select the Currency option in Number . By moving the mouse over the gray boxes at the top of the table header, the cursor changes to resize mode. (Just like you would resize a table in Word.) Use this to resize the entire table, and the columns ( Qty and Line Total can be narrower, while the others might need more space). Finally, emphasize the header row. Select the whole row (by clicking the gray rectangle on the left end of the row) and click Bold on the ribbon. If you check the preview, it should look like this: SUBMISSION If you are continuing with the next exercise, you may omit to create the screenshot here. Create a screenshot of the report preview page. Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible! Upload the changed Visual Studio project and its corresponding files too. Grouping and total value (5p) \u00b6 The report we created is very long, and it contains everything without structure. These are retail sales information: the amount of products sold each day. Let us group the data. Go back to Design tab. Make sure that we see the Row Groups pane below the table. If it is not there, right-click the design area and select Grouping in the View menu. Drag the Date field from Report Data to the Row Groups pane above the (Details) row. The table will look like this: Drag field Order into Row Groups between Date and (Details) . Now there are duplicate columns in the table. Let us delete these. Select the rightmost Date and Order columns by clicking on the gray boxes above them. Delete them by right click and Delete Columns . Unfortunately, the new Date column format is now lost, but you can set it again as previously. Check the Preview now, and see that the table is now ordered and grouped as we specified it. Go back to the Design view. Right-click the [LineTotal] cell and click Add Total . This will add a total for each Order (which we used for grouping). There will be no label added to this line. Add one by left-clicking the cell and typing: \"Order Total\". Holding the CTRL key pressed down, click Order Total , and the two cells to the right to select them all. Then set a background color by choosing one from the Format menu. Check the preview of the report now. Let us create a daily total as well! Go back to the Design view. Right-click on the [Order] cell and click Add Total > After . A new cell (Total) appears below [Order] . Click in it and change the label to \"Daily Total\". Select the cell and the three right next to it (e.g., by using CTRL and clicking them) and change their background color ( Format > Background color ). Since there are quite a few orders per day, you may need to scroll down 4-5 pages to check the result in the preview: SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview, including the lines showing the totals (a turn a few pages if needed to see one). Verify that your Neptun code is visible! Upload the changed Visual Studio project and its corresponding files too.","title":"Exercise 1: Table report"},{"location":"Lab-ReportingServices/Exercise-1/#exercise-1-table-report","text":"This exercise is solved together with the lab instructor. In the checked-out repository, locate file reportserver.sln and open it with Visual Studio. This is an empty Report Server project. The Report Server project consists mainly of Report Definition (.rdl) files, that define the data sources (queries) and a template, which, when rendered, produces the final result: a report. These reports can be installed to a Report Server and executed there, providing the users with up-to-date data. In this lab, we will not use the Report Server. This is mainly because the configuration would require administrative privileges that we do not have in the labs. Therefore, we will preview the reports in Visual Studio.","title":"Exercise 1: Table report"},{"location":"Lab-ReportingServices/Exercise-1/#create-the-first-report-definition-file","text":"In the Solution Explorer right-click Reports and choose Add > New Item . Choose the Report type from among the listed templates. Call it Sales Orders.rdl , then click Add. If adding the new report file fails In certain Visual Studio and Report Server project versions adding this new report file might fail. If this happens, follow these steps instead. Download this empty rdl file . Save the file with the correct name to the reportserver folder of your repository (this folder already exist). In Visual Studio right-click Reports then choose Add > Existing Item , and browse for this file. Open the report file to get the Report Designer view. Here, the new .rdl file is displayed in the Design view. This is our development view. The Report Designer has two views: Design and Preview . A panel called Report Data (on the left) is also opened. Here, we can define data sources. If the data sources are set, we can create the report on the Design tab and check how it would look like on the Preview tab.","title":"Create the first Report Definition file"},{"location":"Lab-ReportingServices/Exercise-1/#configuring-the-data-source","text":"A data source defines where our data comes from. This will be the SQL Server database created before. Using the Report Data pane, click New > Data Source . The name shall be \"AdventureWorks2014\". Choose Microsoft SQL Server as the connection type and click the button to the right of connection string to configure the database access Server name: (localdb)\\mssqllocaldb Authentication: Windows Authentication Select or enter database name: AdventureWorks2014 Click OK to close the dialog. Then re-open the Data Source settings from the Report Data panel by right-clicking on the newly created data source, opening its properties, and then going to the Credentials page. The following checkbox has to be checked:","title":"Configuring the data source"},{"location":"Lab-ReportingServices/Exercise-1/#configuring-a-data-set","text":"The next step is the configuration of a dataset. Practically, this means executing a query in the database. Using the Report Data pane, click New > Data Set . Call the dataset \"AdventureWorksDataset\". Select the data source created before from the dropdown, then apply the following settings: Copy the following query. SELECT soh . OrderDate AS [ Date ], soh . SalesOrderNumber AS [ Order ], pps . Name AS Subcat , pp . Name as Product , SUM ( sd . OrderQty ) AS Qty , SUM ( sd . LineTotal ) AS LineTotal FROM Sales . SalesPerson sp INNER JOIN Sales . SalesOrderHeader AS soh ON sp . BusinessEntityID = soh . SalesPersonID INNER JOIN Sales . SalesOrderDetail AS sd ON sd . SalesOrderID = soh . SalesOrderID INNER JOIN Production . Product AS pp ON sd . ProductID = pp . ProductID INNER JOIN Production . ProductSubcategory AS pps ON pp . ProductSubcategoryID = pps . ProductSubcategoryID INNER JOIN Production . ProductCategory AS ppc ON ppc . ProductCategoryID = pps . ProductCategoryID GROUP BY ppc . Name , soh . OrderDate , soh . SalesOrderNumber , pps . Name , pp . Name , soh . SalesPersonID HAVING ppc . Name = 'Clothing' Click Refresh fields when ready. We have a Query Designer where the query can be created with visual aids. We will not use it, but it is available. Click OK to close the dialog.","title":"Configuring a data set"},{"location":"Lab-ReportingServices/Exercise-1/#table-report-5p","text":"Now that we have our connection to the database and the query that will supply the data, let us create a report. A report is basically data from the database displayed in a table or with diagrams. Open the Toolbox pane. You can do this from the View menu. From the Toolbox choose Table and draw a table on the big, empty and white canvas on the Design tab: Switch back to the Report Data pane and expand the AdventureWorksDataset: If the node is empty or cannot be opened, you need to re-open the data set properties using right-click, then clicking the Refresh Fields button. Drag the Date field to the first column of the table. It should look like this: The [Date] in the second row shows the expression to evaluate, while \"Date\" in the first row is the literal header label - we can change it too. Similarly, add Order and Product to the second and third columns. Add Qty as well: drag it to the right side of the last column; the cursor icon will change to + sign, and a blue line at the end of the table will appear. This will add a new fourth column. Add LineTotal similarly into the fifth column. The first report is almost ready. Let us check how it looks like using the Preview tab. Note that it might take a while for it to open the first time. It will be faster the second time. Verify that your Neptun code appears in the table content! (If not, you forgot a preparation step. Go back, and repeat the steps!) We can print or export the report into various formats (e.g., Word, Excel, PDF). However, this report is not very pretty, e.g., the currency is not displayed, and the Qty and date columns are not formatted, etc. Go back to Design tab, right-click the [Date] expression, and select Text Box Properties. Navigate to the Number page, select the Date category , and choose a date format you like. Right-click [LineTotal] , use Text Box Properties again, and select the Currency option in Number . By moving the mouse over the gray boxes at the top of the table header, the cursor changes to resize mode. (Just like you would resize a table in Word.) Use this to resize the entire table, and the columns ( Qty and Line Total can be narrower, while the others might need more space). Finally, emphasize the header row. Select the whole row (by clicking the gray rectangle on the left end of the row) and click Bold on the ribbon. If you check the preview, it should look like this: SUBMISSION If you are continuing with the next exercise, you may omit to create the screenshot here. Create a screenshot of the report preview page. Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible! Upload the changed Visual Studio project and its corresponding files too.","title":"Table report (5p)"},{"location":"Lab-ReportingServices/Exercise-1/#grouping-and-total-value-5p","text":"The report we created is very long, and it contains everything without structure. These are retail sales information: the amount of products sold each day. Let us group the data. Go back to Design tab. Make sure that we see the Row Groups pane below the table. If it is not there, right-click the design area and select Grouping in the View menu. Drag the Date field from Report Data to the Row Groups pane above the (Details) row. The table will look like this: Drag field Order into Row Groups between Date and (Details) . Now there are duplicate columns in the table. Let us delete these. Select the rightmost Date and Order columns by clicking on the gray boxes above them. Delete them by right click and Delete Columns . Unfortunately, the new Date column format is now lost, but you can set it again as previously. Check the Preview now, and see that the table is now ordered and grouped as we specified it. Go back to the Design view. Right-click the [LineTotal] cell and click Add Total . This will add a total for each Order (which we used for grouping). There will be no label added to this line. Add one by left-clicking the cell and typing: \"Order Total\". Holding the CTRL key pressed down, click Order Total , and the two cells to the right to select them all. Then set a background color by choosing one from the Format menu. Check the preview of the report now. Let us create a daily total as well! Go back to the Design view. Right-click on the [Order] cell and click Add Total > After . A new cell (Total) appears below [Order] . Click in it and change the label to \"Daily Total\". Select the cell and the three right next to it (e.g., by using CTRL and clicking them) and change their background color ( Format > Background color ). Since there are quite a few orders per day, you may need to scroll down 4-5 pages to check the result in the preview: SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f1.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview, including the lines showing the totals (a turn a few pages if needed to see one). Verify that your Neptun code is visible! Upload the changed Visual Studio project and its corresponding files too.","title":"Grouping and total value (5p)"},{"location":"Lab-ReportingServices/Exercise-2/","text":"Exercise 2: Visualization \u00b6 This exercise is to be completed individually for 5 points. The table report shows all sales. That is not useful to get a quick overview. A diagram would be more helpful. Create a diagram that displays the sales per category. Inserting a diagram \u00b6 Switch to Design tab and drag a Chart from the Toolbox to the canvas to the table's right side. You might have to wait a while for the diagram wizard to open. Choose a column diagram. Drag LineTotal from the Report Data pane to the diagram. Do not release the left mouse button. A window will appear beside the diagram. The window is titled Chart Data . Go to the \"\u2211values\" field with your mouse. Release the left mouse button now. This makes the totals be displayed on the vertical axis. Next, drag Subcat field into Category Groups and Date into Series Groups . The horizontal axis displays the categories, and we get separate columns per date series. Right, click label [Date] and select Series Groups Properties . Click on the fx button in Group Expressions . The following expression: =Year(Fields!Date.Value) This will produce a yearly breakdown per category. Press OK in both windows. Before checking the Preview , increase the height of the chart; otherwise, the labels at the bottom will remain hidden: Check the preview now: it shows the sales per category for each year separately. Format the diagram \u00b6 There are a few changes to make. Click Chart title and replace the title: \"Revenue by category NEPTUN\" with your own Neptun code . Right-click <<Expr>> in Series Groups and choose Series Groups Properties . Click on the fx button next to Label . Type: =Year(Fields!Date.Value) . Now the label will be the year part of the date. Right-click the vertical axis and select Vertical Axis Properties . Select Currency from the Number group and fill out as previously: Check the preview now: the diagram will look much better (and also has your Neptun code): SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible in the diagram title! Upload the changed Visual Studio project and its corresponding files too.","title":"Exercise 2: Visualization"},{"location":"Lab-ReportingServices/Exercise-2/#exercise-2-visualization","text":"This exercise is to be completed individually for 5 points. The table report shows all sales. That is not useful to get a quick overview. A diagram would be more helpful. Create a diagram that displays the sales per category.","title":"Exercise 2: Visualization"},{"location":"Lab-ReportingServices/Exercise-2/#inserting-a-diagram","text":"Switch to Design tab and drag a Chart from the Toolbox to the canvas to the table's right side. You might have to wait a while for the diagram wizard to open. Choose a column diagram. Drag LineTotal from the Report Data pane to the diagram. Do not release the left mouse button. A window will appear beside the diagram. The window is titled Chart Data . Go to the \"\u2211values\" field with your mouse. Release the left mouse button now. This makes the totals be displayed on the vertical axis. Next, drag Subcat field into Category Groups and Date into Series Groups . The horizontal axis displays the categories, and we get separate columns per date series. Right, click label [Date] and select Series Groups Properties . Click on the fx button in Group Expressions . The following expression: =Year(Fields!Date.Value) This will produce a yearly breakdown per category. Press OK in both windows. Before checking the Preview , increase the height of the chart; otherwise, the labels at the bottom will remain hidden: Check the preview now: it shows the sales per category for each year separately.","title":"Inserting a diagram"},{"location":"Lab-ReportingServices/Exercise-2/#format-the-diagram","text":"There are a few changes to make. Click Chart title and replace the title: \"Revenue by category NEPTUN\" with your own Neptun code . Right-click <<Expr>> in Series Groups and choose Series Groups Properties . Click on the fx button next to Label . Type: =Year(Fields!Date.Value) . Now the label will be the year part of the date. Right-click the vertical axis and select Vertical Axis Properties . Select Currency from the Number group and fill out as previously: Check the preview now: the diagram will look much better (and also has your Neptun code): SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f2.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible in the diagram title! Upload the changed Visual Studio project and its corresponding files too.","title":"Format the diagram"},{"location":"Lab-ReportingServices/Exercise-3/","text":"Exercise 3: Sales personnel report \u00b6 This exercise is to be completed individually for 5 points. Let us create a new report about the effectiveness of the sales personnel. Extending the data set \u00b6 The dataset we created in the Report Data panel has to be extended with further information. Open the data set properties by right-clicking on AdventureWorksDataSet in the Report Data pane, click Dataset properties then change the SQL command to: SELECT soh . OrderDate AS [ Date ], soh . SalesOrderNumber AS [ Order ], pps . Name AS Subcat , pp . Name as Product , SUM ( sd . OrderQty ) AS Qty , SUM ( sd . LineTotal ) AS LineTotal , CONCAT ( pepe . FirstName , ' ' , pepe . LastName ) AS SalesPersonName FROM Sales . SalesPerson sp INNER JOIN Person . Person as pepe ON sp . BusinessEntityID = pepe . BusinessEntityID INNER JOIN Sales . SalesOrderHeader AS soh ON sp . BusinessEntityID = soh . SalesPersonID INNER JOIN Sales . SalesOrderDetail AS sd ON sd . SalesOrderID = soh . SalesOrderID INNER JOIN Production . Product AS pp ON sd . ProductID = pp . ProductID INNER JOIN Production . ProductSubcategory AS pps ON pp . ProductSubcategoryID = pps . ProductSubcategoryID INNER JOIN Production . ProductCategory AS ppc ON ppc . ProductCategoryID = pps . ProductCategoryID GROUP BY ppc . Name , soh . OrderDate , soh . SalesOrderNumber , pps . Name , pp . Name , soh . SalesPersonID , pepe . FirstName , pepe . LastName HAVING ppc . Name = 'Clothing' Don't forget to press Refresh fields before closing the dialog. Close the dialog. In the Report data expand AdventureWorksDataset (if already expanded, close then re-expand). A new field SalesPersonName will appear. Right-click the data source AdventureWorks2014 and choose Convert to shared Data Source , and then repeat this with the AdventureWorksDataSet too. These will enable us to use them in a new report. New report and data sources \u00b6 We will use the converted and shared data source and data set in a new report. In the Solution Explorer right-click Reports and choose Add > New Item > Report . The name of this new report should be \"Sales People\". Open the new report. There are no data sources associated with the report. Use the Report Data pane to add the existing one: Right-click Data Source and choose Add Data Source Click the Use shared data source reference option and select \"AdventureWorks2014\". Right lick Datasets > Add Dataset Click Use a shared dataset and select the existing AdventureWorksDataset Contents of the report \u00b6 Create a tabular report containing the sales persons and their activity. Group by product category and sales person. Add a total line for each person. Make sure to set appropriate formatting of numbers. The key is creating the table and grouping as below. The category is the field Subcat . The final report should look like this: Tip You should use the Add total > After just like before. But you should do this by clicking on [Subcat] and not [SalesPersonName] ! (If you click SalesPersonName to add the total, it will be a \"grand total\" adding up all persons.) SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible in the table! Upload the changed Visual Studio project and its corresponding files too.","title":"Exercise 3: Sales personnel report"},{"location":"Lab-ReportingServices/Exercise-3/#exercise-3-sales-personnel-report","text":"This exercise is to be completed individually for 5 points. Let us create a new report about the effectiveness of the sales personnel.","title":"Exercise 3: Sales personnel report"},{"location":"Lab-ReportingServices/Exercise-3/#extending-the-data-set","text":"The dataset we created in the Report Data panel has to be extended with further information. Open the data set properties by right-clicking on AdventureWorksDataSet in the Report Data pane, click Dataset properties then change the SQL command to: SELECT soh . OrderDate AS [ Date ], soh . SalesOrderNumber AS [ Order ], pps . Name AS Subcat , pp . Name as Product , SUM ( sd . OrderQty ) AS Qty , SUM ( sd . LineTotal ) AS LineTotal , CONCAT ( pepe . FirstName , ' ' , pepe . LastName ) AS SalesPersonName FROM Sales . SalesPerson sp INNER JOIN Person . Person as pepe ON sp . BusinessEntityID = pepe . BusinessEntityID INNER JOIN Sales . SalesOrderHeader AS soh ON sp . BusinessEntityID = soh . SalesPersonID INNER JOIN Sales . SalesOrderDetail AS sd ON sd . SalesOrderID = soh . SalesOrderID INNER JOIN Production . Product AS pp ON sd . ProductID = pp . ProductID INNER JOIN Production . ProductSubcategory AS pps ON pp . ProductSubcategoryID = pps . ProductSubcategoryID INNER JOIN Production . ProductCategory AS ppc ON ppc . ProductCategoryID = pps . ProductCategoryID GROUP BY ppc . Name , soh . OrderDate , soh . SalesOrderNumber , pps . Name , pp . Name , soh . SalesPersonID , pepe . FirstName , pepe . LastName HAVING ppc . Name = 'Clothing' Don't forget to press Refresh fields before closing the dialog. Close the dialog. In the Report data expand AdventureWorksDataset (if already expanded, close then re-expand). A new field SalesPersonName will appear. Right-click the data source AdventureWorks2014 and choose Convert to shared Data Source , and then repeat this with the AdventureWorksDataSet too. These will enable us to use them in a new report.","title":"Extending the data set"},{"location":"Lab-ReportingServices/Exercise-3/#new-report-and-data-sources","text":"We will use the converted and shared data source and data set in a new report. In the Solution Explorer right-click Reports and choose Add > New Item > Report . The name of this new report should be \"Sales People\". Open the new report. There are no data sources associated with the report. Use the Report Data pane to add the existing one: Right-click Data Source and choose Add Data Source Click the Use shared data source reference option and select \"AdventureWorks2014\". Right lick Datasets > Add Dataset Click Use a shared dataset and select the existing AdventureWorksDataset","title":"New report and data sources"},{"location":"Lab-ReportingServices/Exercise-3/#contents-of-the-report","text":"Create a tabular report containing the sales persons and their activity. Group by product category and sales person. Add a total line for each person. Make sure to set appropriate formatting of numbers. The key is creating the table and grouping as below. The category is the field Subcat . The final report should look like this: Tip You should use the Add total > After just like before. But you should do this by clicking on [Subcat] and not [SalesPersonName] ! (If you click SalesPersonName to add the total, it will be a \"grand total\" adding up all persons.) SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f3.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible in the table! Upload the changed Visual Studio project and its corresponding files too.","title":"Contents of the report"},{"location":"Lab-ReportingServices/Exercise-4/","text":"Exercise 4: Optional exercise \u00b6 You can earn an additional +3 points with the completion of this exercise. Create a pie chart to compare the sales persons' performance according to the total value of purchases achieved by them! Put your Neptun code into the pie chart title! The goal is to get a diagram similar to the one below. Tip The pie chart is similar to the column diagram. The \u2211 Values should be the LineTotal , and Category Groups is the SalesPersonName . ( Series Groups will remain empty this time.) Make sure that the legend shows the names. You might need to adjust the size of the diagram to have enough space. SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible in the diagram title! Upload the changed Visual Studio project and its corresponding files too.","title":"Exercise 4: Optional exercise"},{"location":"Lab-ReportingServices/Exercise-4/#exercise-4-optional-exercise","text":"You can earn an additional +3 points with the completion of this exercise. Create a pie chart to compare the sales persons' performance according to the total value of purchases achieved by them! Put your Neptun code into the pie chart title! The goal is to get a diagram similar to the one below. Tip The pie chart is similar to the column diagram. The \u2211 Values should be the LineTotal , and Category Groups is the SalesPersonName . ( Series Groups will remain empty this time.) Make sure that the legend shows the names. You might need to adjust the size of the diagram to have enough space. SUBMISSION Create a screenshot of the report preview page. Save the screenshot as f4.png and submit it with the other files of the solution. The screenshot shall include Visual Studio and the report preview. Verify that your Neptun code is visible in the diagram title! Upload the changed Visual Studio project and its corresponding files too.","title":"Exercise 4: Optional exercise"}]}